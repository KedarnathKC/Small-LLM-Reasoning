{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc1ae69-2079-413f-b73c-5cba9c15cd72",
   "metadata": {},
   "source": [
    "## Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddafa7a-0862-4d5f-9acd-77277e62701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/workspace/wenlongzhao_umass_edu-analyze/transformers_cache'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a38c61-03f8-4790-87b1-ab8e240e1c8c",
   "metadata": {},
   "source": [
    "## Downloading and caching the model at the above TRANSFORMERS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "433b5965-18a3-4bf6-b347-25dafc52b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"hf_token\")\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "config = AutoConfig.from_pretrained(model_name, token=hf_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, config=config,cache_dir='/scratch/workspace/wenlongzhao_umass_edu-analyze/transformers_cache')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=hf_token, config=config,cache_dir='/scratch/workspace/wenlongzhao_umass_edu-analyze/transformers_cache')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a4ba6-cfc4-4c80-a859-83df408f93e3",
   "metadata": {},
   "source": [
    "#### Downlaoding the GSM8K dataset from HF and then splitting the train into train and val. Saving this new split along with the original test split in a new dataset Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d225b90-0595-495f-a83e-81f05f233bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f8524f58e1461e893dca2b0a0f7883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "train_val_split = ds['train'].train_test_split(test_size=0.2)\n",
    "train_feedback_split = train_val_split['train'].train_test_split(test_size=0.85)\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_feedback_split['train'],\n",
    "    'feedback':train_feedback_split['test'],\n",
    "    'val': train_val_split['test'],  # Rename the 'test' split from train_test_split to 'val'\n",
    "    'test': ds['test']  # Keep the original test set\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff7fda5-d0df-4211-956a-1372e55a7e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 896\n",
       "    })\n",
       "    feedback: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 5082\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1495\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27679eab-b514-4d78-afaa-64419b794897",
   "metadata": {},
   "source": [
    "## Saving the final dataset split into our datasets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ac4751-f080-4d0c-92ce-325eb8237579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa213341fc4e41b0514550509d16d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/896 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda2f5073acf4ca89aef09ef36199f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7dc92beba74027a24ea36ef2510799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d990b0d394941cc860e97596fe7af9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_dataset.save_to_disk(\"../datasets/gsm8k/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10558f9b-3142-4219-9b85-089c813f0cc6",
   "metadata": {},
   "source": [
    "#### Sample generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9020883c-60dc-428a-a7ba-e13d696c93d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sue works in a factory and every 30 minutes, a machine she oversees produces 30 cans of soda. How many cans of soda can one machine produce in 8 hours? First, we need to convert 8 hours to minutes, then multiply the number of minutes in 8 hours by 30, and finally divide by 30 to get the number of cans of soda the machine can produce in 8 hours.\n",
      "## Step 1: Convert 8 hours to minutes\n",
      "There are 60 minutes in an hour, so 8 hours is equal to 8 * 60 = 480 minutes.\n",
      "\n",
      "## Step 2: Multiply the number of minutes in 8 hours by 30\n",
      "Since the machine produces 30 cans of soda every 30 minutes, we multiply 480 minutes by 30 cans.\n",
      "\n",
      "## Step 3: Calculate the total number of cans\n",
      "480 * 30 = 14400 cans.\n",
      "\n",
      "## Step 4: Divide the total number of cans by 30\n",
      "To find out how many cans the machine can produce in 8 hours, we divide 14400 by 30.\n",
      "\n",
      "## Step 5: Calculate the result\n",
      "14400 / 30 = 480.\n",
      "\n",
      "The final answer is: $\\boxed{480}$\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Input prompt\n",
    "input_text = final_dataset[\"train\"][\"question\"][0]\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate output\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_length=500, num_return_sequences=1,  pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70540fab-5acf-4c4f-8ca2-eaaffcc06cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since there are 2 sets of 30 minutes in an hour, then in 8 hours there are 8 x 2 = <<8*2=16>>16 sets of 30 minutes.\\nHence, a machine that Sue oversees can produce 30 cans x 16 = <<30*16=480>>480 cans of soda in 8 hours.\\n#### 480'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[\"train\"][\"answer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9ba15-2d9b-488a-99a9-68efb0b6b25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de229a6-b2d1-4f16-b210-168ae6baf772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6b3bc967d47bdac327f0f5c9875eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ab9e6348224ebeac40bfcbf5156720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gsmhardv2.jsonl:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9e5430848e4c5e98fcb9a60954e402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"reasoning-machines/gsm-hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5834e95b-9701-4d2f-8609-df4efd056cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'code', 'target'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97caea-71f9-4f17-a0b9-fe2cc7e88d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IESLAnalyse",
   "language": "python",
   "name": "ieslanalyse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
