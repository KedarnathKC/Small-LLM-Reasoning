gpu024
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.34s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.38s/it]
Processing questions:   0%|          | 0/21 [00:00<?, ?it/s]/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Processing questions:   5%|▍         | 1/21 [02:18<46:15, 138.79s/it]Processing questions:  10%|▉         | 2/21 [04:38<44:06, 139.31s/it]Processing questions:  14%|█▍        | 3/21 [06:59<42:01, 140.06s/it]Processing questions:  19%|█▉        | 4/21 [09:18<39:36, 139.76s/it]Processing questions:  24%|██▍       | 5/21 [11:30<36:30, 136.89s/it]Processing questions:  29%|██▊       | 6/21 [13:50<34:28, 137.88s/it]Processing questions:  33%|███▎      | 7/21 [16:09<32:14, 138.20s/it]Processing questions:  38%|███▊      | 8/21 [18:30<30:10, 139.23s/it]Processing questions:  43%|████▎     | 9/21 [20:31<26:40, 133.37s/it]Processing questions:  48%|████▊     | 10/21 [22:50<24:47, 135.24s/it]Processing questions:  52%|█████▏    | 11/21 [24:51<21:49, 130.97s/it]Processing questions:  57%|█████▋    | 12/21 [27:10<20:01, 133.45s/it]Processing questions:  62%|██████▏   | 13/21 [29:30<18:01, 135.25s/it]Processing questions:  67%|██████▋   | 14/21 [31:49<15:55, 136.51s/it]Processing questions:  71%|███████▏  | 15/21 [34:09<13:45, 137.57s/it]Processing questions:  76%|███████▌  | 16/21 [36:31<11:33, 138.74s/it]Processing questions:  81%|████████  | 17/21 [38:57<09:23, 140.92s/it]Processing questions:  86%|████████▌ | 18/21 [41:15<07:00, 140.22s/it]Processing questions:  90%|█████████ | 19/21 [43:39<04:42, 141.22s/it]Processing questions:  95%|█████████▌| 20/21 [45:59<02:20, 140.95s/it]Processing questions: 100%|██████████| 21/21 [47:19<00:00, 122.61s/it]Processing questions: 100%|██████████| 21/21 [47:19<00:00, 135.22s/it]
SCORE of LLaMA 8B Model is:  0.8021228203184231
