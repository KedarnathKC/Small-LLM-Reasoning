gpu022
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.17it/s]
Processing questions:   0%|          | 0/21 [00:00<?, ?it/s]/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Processing questions:   5%|▍         | 1/21 [00:33<11:06, 33.31s/it]Processing questions:  10%|▉         | 2/21 [01:09<11:03, 34.93s/it]Processing questions:  14%|█▍        | 3/21 [01:45<10:35, 35.31s/it]Processing questions:  19%|█▉        | 4/21 [02:21<10:04, 35.58s/it]Processing questions:  24%|██▍       | 5/21 [02:50<08:55, 33.50s/it]Processing questions:  29%|██▊       | 6/21 [03:24<08:20, 33.39s/it]Processing questions:  33%|███▎      | 7/21 [03:59<07:58, 34.20s/it]Processing questions:  38%|███▊      | 8/21 [04:36<07:33, 34.90s/it]Processing questions:  43%|████▎     | 9/21 [05:05<06:38, 33.17s/it]Processing questions:  48%|████▊     | 10/21 [05:38<06:04, 33.10s/it]Processing questions:  52%|█████▏    | 11/21 [06:14<05:38, 33.83s/it]Processing questions:  57%|█████▋    | 12/21 [06:48<05:04, 33.87s/it]Processing questions:  62%|██████▏   | 13/21 [07:24<04:36, 34.51s/it]Processing questions:  67%|██████▋   | 14/21 [08:00<04:04, 34.96s/it]Processing questions:  71%|███████▏  | 15/21 [08:36<03:31, 35.31s/it]Processing questions:  76%|███████▌  | 16/21 [09:12<02:58, 35.65s/it]Processing questions:  81%|████████  | 17/21 [09:50<02:24, 36.22s/it]Processing questions:  86%|████████▌ | 18/21 [10:25<01:48, 36.08s/it]Processing questions:  90%|█████████ | 19/21 [11:02<01:12, 36.35s/it]Processing questions:  95%|█████████▌| 20/21 [11:32<00:34, 34.36s/it]Processing questions: 100%|██████████| 21/21 [11:50<00:00, 29.40s/it]Processing questions: 100%|██████████| 21/21 [11:50<00:00, 33.83s/it]
SCORE of LLaMA 3B Model with bfloat16 is:  0.7520849128127369
