gpu022
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.37s/it]
Processing questions:   0%|          | 0/21 [00:00<?, ?it/s]/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Processing questions:   5%|▍         | 1/21 [01:19<26:32, 79.65s/it]Processing questions:  10%|▉         | 2/21 [02:36<24:44, 78.15s/it]Processing questions:  14%|█▍        | 3/21 [03:54<23:22, 77.91s/it]Processing questions:  19%|█▉        | 4/21 [05:11<21:57, 77.52s/it]Processing questions:  24%|██▍       | 5/21 [06:23<20:12, 75.76s/it]Processing questions:  29%|██▊       | 6/21 [07:33<18:26, 73.74s/it]Processing questions:  33%|███▎      | 7/21 [08:50<17:25, 74.68s/it]Processing questions:  38%|███▊      | 8/21 [10:08<16:24, 75.70s/it]Processing questions:  43%|████▎     | 9/21 [11:24<15:10, 75.85s/it]Processing questions:  48%|████▊     | 10/21 [12:41<13:57, 76.17s/it]Processing questions:  52%|█████▏    | 11/21 [13:58<12:45, 76.52s/it]Processing questions:  57%|█████▋    | 12/21 [15:15<11:29, 76.58s/it]Processing questions:  62%|██████▏   | 13/21 [16:32<10:13, 76.67s/it]Processing questions:  67%|██████▋   | 14/21 [17:49<08:57, 76.74s/it]Processing questions:  71%|███████▏  | 15/21 [19:06<07:41, 76.87s/it]Processing questions:  76%|███████▌  | 16/21 [20:24<06:25, 77.19s/it]Processing questions:  81%|████████  | 17/21 [21:44<05:12, 78.14s/it]Processing questions:  86%|████████▌ | 18/21 [23:00<03:52, 77.61s/it]Processing questions:  90%|█████████ | 19/21 [24:20<02:36, 78.08s/it]Processing questions:  95%|█████████▌| 20/21 [25:36<01:17, 77.42s/it]Processing questions: 100%|██████████| 21/21 [26:16<00:00, 66.22s/it]Processing questions: 100%|██████████| 21/21 [26:16<00:00, 75.05s/it]
SCORE of LLaMA 3B Model is:  0.7323730098559514
