gpu028
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|█████     | 1/2 [01:57<01:57, 117.78s/it]Downloading shards: 100%|██████████| 2/2 [02:32<00:00, 69.08s/it] Downloading shards: 100%|██████████| 2/2 [02:32<00:00, 76.39s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
Processing questions:   0%|          | 0/21 [00:00<?, ?it/s]/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kchimmad_umass_edu/.conda/envs/IESLAnalyse/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Processing questions:   5%|▍         | 1/21 [00:45<15:16, 45.81s/it]Processing questions:  10%|▉         | 2/21 [01:26<13:34, 42.88s/it]Processing questions:  14%|█▍        | 3/21 [02:06<12:23, 41.32s/it]Processing questions:  19%|█▉        | 4/21 [02:46<11:38, 41.11s/it]Processing questions:  24%|██▍       | 5/21 [03:27<10:52, 40.79s/it]Processing questions:  29%|██▊       | 6/21 [04:02<09:45, 39.04s/it]Processing questions:  33%|███▎      | 7/21 [04:40<08:58, 38.49s/it]Processing questions:  38%|███▊      | 8/21 [05:21<08:32, 39.40s/it]Processing questions:  43%|████▎     | 9/21 [06:01<07:56, 39.71s/it]Processing questions:  48%|████▊     | 10/21 [06:42<07:20, 40.05s/it]Processing questions:  52%|█████▏    | 11/21 [07:23<06:43, 40.36s/it]Processing questions:  57%|█████▋    | 12/21 [07:55<05:40, 37.83s/it]Processing questions:  62%|██████▏   | 13/21 [08:36<05:09, 38.73s/it]Processing questions:  67%|██████▋   | 14/21 [09:17<04:35, 39.36s/it]Processing questions:  71%|███████▏  | 15/21 [09:58<03:59, 39.85s/it]Processing questions:  76%|███████▌  | 16/21 [10:39<03:21, 40.31s/it]Processing questions:  81%|████████  | 17/21 [11:22<02:44, 41.05s/it]Processing questions:  86%|████████▌ | 18/21 [12:03<02:02, 40.89s/it]Processing questions:  90%|█████████ | 19/21 [12:45<01:22, 41.26s/it]Processing questions:  95%|█████████▌| 20/21 [13:25<00:40, 40.88s/it]Processing questions: 100%|██████████| 21/21 [13:44<00:00, 34.37s/it]Processing questions: 100%|██████████| 21/21 [13:44<00:00, 39.25s/it]
SCORE of LLaMA 3B Model is:  0.7285822592873389
