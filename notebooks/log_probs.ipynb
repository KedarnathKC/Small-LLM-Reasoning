{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6250c7-7ab8-4609-a21b-c2116bf381eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME']=cache_dir\n",
    "os.environ['HF_HUB_CACHE']=cache_dir+'/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4816db-7562-42d9-8a72-9384bc329a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, load_dataset\n",
    "# from small_llm_reasoning.generation.transformers_generation import generation\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f860d8-c3e7-4aae-9044-d55bfed5efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'token_ids', 'log_probs', 'all_returned_log_probs', 'model_answer', 'GT_Answer', 'score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = load_dataset('json',data_files='/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/outputs/exp-2.0.1/eval_1/generated_outputs.json')['train']\n",
    "student_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924fb1d9-dbb2-442b-aaf9-074e3fb9fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'input_ids'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data_path= \"../datasets/gsm8k\"\n",
    "split='feedback'\n",
    "data = load_from_disk(f\"{data_path}/tokenized/LLaMA3B-Instruct/{split}/zero-shot/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1079e8c9-212f-4f87-a62f-410ccce2e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "padding='longest'\n",
    "padding_side=None\n",
    "special_tokens=False\n",
    "torch_dtype='bfloat16'\n",
    "hf_token=os.getenv('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60383bff-11c5-4ff3-ac7b-fdb69eae5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.45s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        token=hf_token, \n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch_dtype,\n",
    "    token=hf_token, \n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "if padding_side:\n",
    "        tokenizer.padding_side = padding_side\n",
    "add_special_tokens = {\"add_special_tokens\": special_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4de3090-fbd1-4a05-a57c-1fe98e14fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(q,a):\n",
    "    return q+a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34a46b8a-dc56-46bb-be6b-296d50c4bf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[13997,   451]], device='cuda:0'), 'attention_mask': tensor([[1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('abcde', padding=padding, return_tensors=\"pt\", **add_special_tokens).to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c38f6e8f-5038-4a5e-850d-5b1226335624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX:\n",
      "0\n",
      "Prompts:\n",
      "tensor([128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "            25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "           220,    605,   2947,    220,   2366,     20,    271, 128009, 128006,\n",
      "           882, 128007,    271,  22818,    279,   2768,   3575,     11,   2944,\n",
      "           323,   3041,    264,   1620,   4320,    311,    279,   3575,    627,\n",
      "         32298,     25,    362,   3830,    374,    220,     23,  15271,    304,\n",
      "          2673,     11,    220,    605,  15271,    304,   2430,     11,    323,\n",
      "           220,    717,  15271,    304,   3160,     13,    362,  23162,   4857,\n",
      "          2565,    374,    220,     18,  15271,    304,   2673,     11,    220,\n",
      "            17,  15271,    304,   2430,     11,    323,    220,     19,  15271,\n",
      "           304,   3160,     13,   2650,   1690,   4857,  10215,    649,   5052,\n",
      "          1139,    279,   3830,   5380,   7927,   2077,   1288,    842,    449,\n",
      "           330,    791,   1620,   4320,    374,    510,   9399,  19727,   1405,\n",
      "           510,   9399,     60,    374,    279,   2077,    311,    279,   3575,\n",
      "            13, 128009, 128006,  78191, 128007,    271,   1271,   1505,    704,\n",
      "          1268,   1690,   4857,  10215,    649,   5052,   1139,    279,   3830,\n",
      "            11,    584,   1205,    311,  22497,    279,   8286,    315,    279,\n",
      "          3830,    555,    279,   8286,    315,    264,   3254,   4857,   2565,\n",
      "           382,    791,   8286,    315,    279,   3830,    374,  16997,    555,\n",
      "         85292,   1202,   2673,     11,   2430,     11,    323,   3160,    512,\n",
      "         19436,    315,   3830,    284,   2673,    353,   2430,    353,   3160,\n",
      "           284,    220,     23,    353,    220,    605,    353,    220,    717,\n",
      "           284,    220,  16415,  41999,  15271,    271,    791,   8286,    315,\n",
      "           264,   3254,   4857,   2565,    374,  16997,    555,  85292,   1202,\n",
      "          2673,     11,   2430,     11,    323,   3160,    512,  19436,    315,\n",
      "          4857,   2565,    284,   2673,    353,   2430,    353,   3160,    284,\n",
      "           220,     18,    353,    220,     17,    353,    220,     19,    284,\n",
      "           220,   1187,  41999,  15271,    271,   7184,     11,    584,  22497,\n",
      "           279,   8286,    315,    279,   3830,    555,    279,   8286,    315,\n",
      "           264,   3254,   4857,   2565,    311,   1505,    704,   1268,   1690,\n",
      "         10215,    649,   5052,    512,   2903,    315,  10215,    284,  20880,\n",
      "           315,   3830,    611,  20880,    315,   4857,   2565,    284,    220,\n",
      "         16415,    611,    220,   1187,    284,    220,   1272,    271,    791,\n",
      "          1620,   4320,    374,    220,   1272,     13, 128009],\n",
      "       device='cuda:0')\n",
      "Answer_Token_Ids:\n",
      "[1271, 1505, 704, 1268, 1690, 4857, 10215, 649, 5052, 1139, 279, 3830, 11, 584, 1205, 311, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 382, 791, 8286, 315, 279, 3830, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 3830, 284, 2673, 353, 2430, 353, 3160, 284, 220, 23, 353, 220, 605, 353, 220, 717, 284, 220, 16415, 41999, 15271, 271, 791, 8286, 315, 264, 3254, 4857, 2565, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 4857, 2565, 284, 2673, 353, 2430, 353, 3160, 284, 220, 18, 353, 220, 17, 353, 220, 19, 284, 220, 1187, 41999, 15271, 271, 7184, 11, 584, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 311, 1505, 704, 1268, 1690, 10215, 649, 5052, 512, 2903, 315, 10215, 284, 20880, 315, 3830, 611, 20880, 315, 4857, 2565, 284, 220, 16415, 611, 220, 1187, 284, 220, 1272, 271, 791, 1620, 4320, 374, 220, 1272, 13, 128009]\n",
      "Answer:\n",
      "To find out how many building blocks can fit into the box, we need to divide the volume of the box by the volume of a single building block.\n",
      "\n",
      "The volume of the box is calculated by multiplying its height, width, and length:\n",
      "Volume of box = height * width * length = 8 * 10 * 12 = 960 cubic inches\n",
      "\n",
      "The volume of a single building block is calculated by multiplying its height, width, and length:\n",
      "Volume of building block = height * width * length = 3 * 2 * 4 = 24 cubic inches\n",
      "\n",
      "Now, we divide the volume of the box by the volume of a single building block to find out how many blocks can fit:\n",
      "Number of blocks = Volume of box / Volume of building block = 960 / 24 = 40\n",
      "\n",
      "The final answer is 40.\n",
      "[[-29.625, -18.25, -20.125, -24.875, -22.875, -27.875, -29.875, -23.75, -19.375, -27.625, -23.125, -24.25, -29.875, -16.625, -23.75, -19.5, -24.0, -20.25, -18.625, -25.75, -24.625, -21.625, -26.5, -22.25, -21.75, -20.5, -22.125, -20.125, -22.0, -21.25, -26.5, -33.0, -23.25, -24.625, -25.0, -19.75, -17.375, -24.25, -19.125, -25.375, -21.25, -19.0, -33.25, -25.5, -29.125, -27.375, -19.875, -24.25, -25.125, -23.125, -20.25, -21.25, -17.75, -25.5, -24.75, -24.625, -27.375, -25.0, -19.75, -27.875, -20.125, -21.125, -34.5, -22.25, -18.875, -29.875, -24.75, -16.625, -24.625, -21.25, -18.875, -27.25, -31.375, -25.25, -23.0, -18.625, -20.875, -25.375, -22.25, -19.625, -21.5, -21.5, -27.25, -21.25, -21.125, -26.75, -23.5, -24.0, -23.625, -25.5, -25.75, -32.5, -20.0, -23.625, -15.6875, -19.875, -22.75, -23.875, -24.0, -21.75, -22.5, -20.625, -15.125, -29.0, -22.0, -17.5, -31.75, -20.25, -16.875, -26.625, -23.0, -26.625, -31.0, -18.375, -20.125, -32.0, -32.0, -26.375, -18.75, -24.25, -24.625, -26.75, -27.5, -27.5, -26.625, -27.75, -24.875, -25.25, -22.25, -20.875, -24.625, -22.875, -24.125, -22.875, -18.25, -17.125, -22.75, -19.875, -29.25, -22.75, -16.75, -24.875, -34.5, -23.875, -27.0, -23.25, -29.0, -26.25, -26.0, -24.0, -32.0, -20.375, -24.25, -28.25, -24.875, -13.75, -25.875, -23.25, -15.125, -31.5, -25.25, -21.75, -28.5, -28.125, -31.375, -31.5, -25.25, -21.875, -25.0, -29.375, -33.75, -9.25]]\n",
      "172\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "answer_log_probs = []\n",
    "for i in range(data.num_rows):\n",
    "    question= data['input_ids'][i]['prompt_token_ids']\n",
    "    answer= student_data['token_ids'][i][0] \n",
    "    example= question + answer\n",
    "    example=torch.tensor(example, dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "    answer=[answer]\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(example)\n",
    "    \n",
    "    # Extract logits\n",
    "    logits = outputs.logits  # Shape: [batch_size, seq_len, vocab_size]\n",
    "    \n",
    "    \n",
    "    # Convert logits to log probabilities\n",
    "    log_probs = F.log_softmax(logits,dim=-1) # Shape: [batch_size, seq_len, vocab_size]\n",
    "    \n",
    "    # Identify the token IDs for the answer (without special tokens)\n",
    "    \n",
    "    answer_tokens = []\n",
    "    answer_token_idxs=[]\n",
    "    \n",
    "    \n",
    "    for idx, (prompt, answer_tokens_ids) in enumerate(zip(example, answer)):\n",
    "        # Extract token IDs for answer tokens in the concatenated input\n",
    "        print(f'IDX:\\n{idx}')\n",
    "        print(f'Prompts:\\n{prompt}')\n",
    "        print(f'Answer_Token_Ids:\\n{answer_tokens_ids}')\n",
    "        answer_start_idx = (example[idx] == answer_tokens_ids[0]).nonzero(as_tuple=True)[0][0].item()\n",
    "        answer_end_idx = answer_start_idx + len(answer_tokens_ids)\n",
    "        answer_tokens.append(example[idx, answer_start_idx:answer_end_idx])\n",
    "        print(f'Answer:\\n{tokenizer.decode(example[idx, answer_start_idx:answer_end_idx], skip_special_tokens=True)}')\n",
    "        # answer_token_idxs.append(list(range(answer_start_idx, answer_end_idx)))\n",
    "        answer_token_idxs.append([answer_start_idx,answer_end_idx])\n",
    "\n",
    "    # Now, extract the log probs for the selected tokens (answer tokens)\n",
    "    for i, tokens in enumerate(answer_tokens):\n",
    "        # answer_positions = torch.tensor(answer_token_idxs[i], device=model.device)  # Convert to tensor\n",
    "        selected_log_probs = log_probs[i, answer_token_idxs[i][0]:answer_token_idxs[i][1]].gather(dim=-1, index=tokens.unsqueeze(-1)).squeeze(-1)\n",
    "        answer_log_probs.append(selected_log_probs.tolist())\n",
    "    print(answer_log_probs)\n",
    "    print(len(answer_log_probs[i]))\n",
    "    print(len(student_data['log_probs'][i][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26438a3d-9fcc-43d1-a015-4525c57400ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57ea74-2605-404c-9a7f-2d9d90c1035e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3dc63ba-3148-4c29-92c0-f746dd4fd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.num_rows):\n",
    "    assert len(data[i]['log_probs'][0])==len(data[i]['all_returned_log_probs'])\n",
    "    assert len(data[i]['log_probs'][0])==len(data[i]['token_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9fcaae9-c95e-4da4-868b-39457cada8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "padding='longest'\n",
    "padding_side=None\n",
    "special_tokens=False\n",
    "torch_dtype='bfloat16'\n",
    "hf_token=os.getenv('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e99ea03-33b3-4f8a-9fed-699ee938d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        token=hf_token, \n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch_dtype,\n",
    "    token=hf_token, \n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "if padding_side:\n",
    "        tokenizer.padding_side = padding_side\n",
    "add_special_tokens = {\"add_special_tokens\": special_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "922e81a1-728f-4612-83d2-ec5efc79a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(q,a):\n",
    "    return q+a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a45dd0a-07aa-444f-9f06-849a71742276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1271, 1505, 704, 1268, 1690, 4857, 10215, 649, 5052, 1139, 279, 3830, 11, 584, 1205, 311, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 382, 791, 8286, 315, 279, 3830, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 3830, 284, 2673, 353, 2430, 353, 3160, 284, 220, 23, 353, 220, 605, 353, 220, 717, 284, 220, 16415, 41999, 15271, 271, 791, 8286, 315, 264, 3254, 4857, 2565, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 4857, 2565, 284, 2673, 353, 2430, 353, 3160, 284, 220, 18, 353, 220, 17, 353, 220, 19, 284, 220, 1187, 41999, 15271, 271, 7184, 11, 584, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 311, 1505, 704, 1268, 1690, 10215, 649, 5052, 512, 2903, 315, 10215, 284, 20880, 315, 3830, 611, 20880, 315, 4857, 2565, 284, 220, 16415, 611, 220, 1187, 284, 220, 1272, 271, 791, 1620, 4320, 374, 220, 1272, 13]\n",
      "171\n",
      "To find out how many building blocks can fit into the box, we need to divide the volume of the box by the volume of a single building block.\n",
      "\n",
      "The volume of the box is calculated by multiplying its height, width, and length:\n",
      "Volume of box = height * width * length = 8 * 10 * 12 = 960 cubic inches\n",
      "\n",
      "The volume of a single building block is calculated by multiplying its height, width, and length:\n",
      "Volume of building block = height * width * length = 3 * 2 * 4 = 24 cubic inches\n",
      "\n",
      "Now, we divide the volume of the box by the volume of a single building block to find out how many blocks can fit:\n",
      "Number of blocks = Volume of box / Volume of building block = 960 / 24 = 40\n",
      "\n",
      "The final answer is 40.\n"
     ]
    }
   ],
   "source": [
    "# HF\n",
    "output=tokenizer(data['output'][0][0],return_tensors=\"pt\", **add_special_tokens)\n",
    "tokens=output['input_ids'].tolist()[0]\n",
    "print(tokens)\n",
    "print(len(tokens))\n",
    "print(tokenizer.decode(tokens, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45e16323-c594-42e2-a684-847385a70ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1271, 1505, 704, 1268, 1690, 4857, 10215, 649, 5052, 1139, 279, 3830, 11, 584, 1205, 311, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 382, 791, 8286, 315, 279, 3830, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 3830, 284, 2673, 353, 2430, 353, 3160, 284, 220, 23, 353, 220, 605, 353, 220, 717, 284, 220, 16415, 41999, 15271, 271, 791, 8286, 315, 264, 3254, 4857, 2565, 374, 16997, 555, 85292, 1202, 2673, 11, 2430, 11, 323, 3160, 512, 19436, 315, 4857, 2565, 284, 2673, 353, 2430, 353, 3160, 284, 220, 18, 353, 220, 17, 353, 220, 19, 284, 220, 1187, 41999, 15271, 271, 7184, 11, 584, 22497, 279, 8286, 315, 279, 3830, 555, 279, 8286, 315, 264, 3254, 4857, 2565, 311, 1505, 704, 1268, 1690, 10215, 649, 5052, 512, 2903, 315, 10215, 284, 20880, 315, 3830, 611, 20880, 315, 4857, 2565, 284, 220, 16415, 611, 220, 1187, 284, 220, 1272, 271, 791, 1620, 4320, 374, 220, 1272, 13, 128009]\n",
      "172\n",
      "To find out how many building blocks can fit into the box, we need to divide the volume of the box by the volume of a single building block.\n",
      "\n",
      "The volume of the box is calculated by multiplying its height, width, and length:\n",
      "Volume of box = height * width * length = 8 * 10 * 12 = 960 cubic inches\n",
      "\n",
      "The volume of a single building block is calculated by multiplying its height, width, and length:\n",
      "Volume of building block = height * width * length = 3 * 2 * 4 = 24 cubic inches\n",
      "\n",
      "Now, we divide the volume of the box by the volume of a single building block to find out how many blocks can fit:\n",
      "Number of blocks = Volume of box / Volume of building block = 960 / 24 = 40\n",
      "\n",
      "The final answer is 40.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# vLLM\n",
    "print(data['token_ids'][0][0])\n",
    "print(len(data['token_ids'][0][0]))\n",
    "print(tokenizer.decode(data['token_ids'][0][0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4358e0c-c053-4a84-ae6b-292273aa82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how many building blocks can fit into the box, we need to divide the volume of the box by the volume of a single building block.\n",
      "\n",
      "The volume of the box is calculated by multiplying its height, width, and length:\n",
      "Volume of box = height * width * length = 8 * 10 * 12 = 960 cubic inches\n",
      "\n",
      "The volume of a single building block is calculated by multiplying its height, width, and length:\n",
      "Volume of building block = height * width * length = 3 * 2 * 4 = 24 cubic inches\n",
      "\n",
      "Now, we divide the volume of the box by the volume of a single building block to find out how many blocks can fit:\n",
      "Number of blocks = Volume of box / Volume of building block = 960 / 24 = 40\n",
      "\n",
      "The final answer is 40.\n"
     ]
    }
   ],
   "source": [
    "print(data['output'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db44c26c-e897-44dd-8762-3d8fdd1d51f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1271, 1505, 704, 1268, 1690, 2678, 6136, 388, 15796, 41033, 3966, 11, 584, 1176, 1205, 311, 8417, 1268, 1690, 19595, 568, 649, 6136, 304, 279, 3544, 6136, 388, 13, 4815, 1548, 706, 220, 19, 3544, 6136, 388, 430, 649, 3412, 220, 508, 19595, 1855, 11, 779, 279, 2860, 1396, 315, 19595, 568, 649, 6136, 304, 279, 3544, 6136, 388, 374, 512, 19, 6136, 388, 353, 220, 508, 19595, 14, 10609, 466, 284, 220, 1490, 19595, 271, 7184, 11, 584, 33356, 279, 19595, 39441, 304, 279, 3544, 6136, 388, 505, 279, 2860, 1396, 315, 19595, 512, 1049, 19595, 482, 220, 1490, 19595, 284, 220, 4364, 19595, 271, 12834, 279, 2678, 6136, 388, 649, 3412, 220, 19, 19595, 1855, 11, 584, 22497, 279, 9861, 19595, 555, 220, 19, 311, 1505, 704, 1268, 1690, 2678, 6136, 388, 527, 4460, 512, 4364, 19595, 611, 220, 19, 19595, 14, 10609, 466, 284, 220, 966, 6136, 388, 271, 791, 1620, 4320, 374, 220, 966, 13]\n",
      "159\n",
      "To find out how many small planters Oshea needs, we first need to determine how many seeds he can plant in the large planters. \n",
      "\n",
      "He has 4 large planters that can hold 20 seeds each, so the total number of seeds he can plant in the large planters is:\n",
      "4 planters * 20 seeds/planter = 80 seeds\n",
      "\n",
      "Now, we subtract the seeds planted in the large planters from the total number of seeds:\n",
      "200 seeds - 80 seeds = 120 seeds\n",
      "\n",
      "Since the small planters can hold 4 seeds each, we divide the remaining seeds by 4 to find out how many small planters are needed:\n",
      "120 seeds / 4 seeds/planter = 30 planters\n",
      "\n",
      "The final answer is 30.\n"
     ]
    }
   ],
   "source": [
    "# HF\n",
    "output=tokenizer(data['output'][143][0],return_tensors=\"pt\", **add_special_tokens)\n",
    "tokens=output['input_ids'].tolist()[0]\n",
    "print(tokens)\n",
    "print(len(tokens))\n",
    "print(tokenizer.decode(tokens, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32a856ab-ecd0-4954-8dd2-0a19d8c626a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/planter'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([14 ,10609 ,466])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec1385b5-2313-427e-9091-85fe1f519307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/planter'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([11505 ,81130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49b58eea-782b-4845-b8f3-c8befa2f164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1271, 1505, 704, 1268, 1690, 2678, 6136, 388, 15796, 41033, 3966, 11, 584, 1176, 1205, 311, 8417, 1268, 1690, 19595, 568, 649, 6136, 304, 279, 3544, 6136, 388, 13, 4815, 1548, 706, 220, 19, 3544, 6136, 388, 430, 649, 3412, 220, 508, 19595, 1855, 11, 779, 279, 2860, 1396, 315, 19595, 568, 649, 6136, 304, 279, 3544, 6136, 388, 374, 512, 19, 6136, 388, 353, 220, 508, 19595, 11505, 81130, 284, 220, 1490, 19595, 271, 7184, 11, 584, 33356, 279, 19595, 39441, 304, 279, 3544, 6136, 388, 505, 279, 2860, 1396, 315, 19595, 512, 1049, 19595, 482, 220, 1490, 19595, 284, 220, 4364, 19595, 271, 12834, 279, 2678, 6136, 388, 649, 3412, 220, 19, 19595, 1855, 11, 584, 22497, 279, 9861, 19595, 555, 220, 19, 311, 1505, 704, 1268, 1690, 2678, 6136, 388, 527, 4460, 512, 4364, 19595, 611, 220, 19, 19595, 11505, 81130, 284, 220, 966, 6136, 388, 271, 791, 1620, 4320, 374, 220, 966, 13, 128009]\n",
      "158\n",
      "To find out how many small planters Oshea needs, we first need to determine how many seeds he can plant in the large planters. \n",
      "\n",
      "He has 4 large planters that can hold 20 seeds each, so the total number of seeds he can plant in the large planters is:\n",
      "4 planters * 20 seeds/planter = 80 seeds\n",
      "\n",
      "Now, we subtract the seeds planted in the large planters from the total number of seeds:\n",
      "200 seeds - 80 seeds = 120 seeds\n",
      "\n",
      "Since the small planters can hold 4 seeds each, we divide the remaining seeds by 4 to find out how many small planters are needed:\n",
      "120 seeds / 4 seeds/planter = 30 planters\n",
      "\n",
      "The final answer is 30.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# vLLM\n",
    "print(data['token_ids'][143][0])\n",
    "print(len(data['token_ids'][143][0]))\n",
    "print(tokenizer.decode(data['token_ids'][143][0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47cda566-f593-461e-91ea-2dcc9f88abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how many building blocks can fit into the box, we need to divide the volume of the box by the volume of a single building block.\n",
      "\n",
      "The volume of the box is calculated by multiplying its height, width, and length:\n",
      "Volume of box = height * width * length = 8 * 10 * 12 = 960 cubic inches\n",
      "\n",
      "The volume of a single building block is calculated by multiplying its height, width, and length:\n",
      "Volume of building block = height * width * length = 3 * 2 * 4 = 24 cubic inches\n",
      "\n",
      "Now, we divide the volume of the box by the volume of a single building block to find out how many blocks can fit:\n",
      "Number of blocks = Volume of box / Volume of building block = 960 / 24 = 40\n",
      "\n",
      "The final answer is 40.\n"
     ]
    }
   ],
   "source": [
    "print(data['output'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bd533f-cecc-4f07-ab53-135b075b3751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:15<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size=1\n",
    "answer_log_probs = []\n",
    "for i in tqdm(range(0,data.num_rows,batch_size)):\n",
    "    questions=data['input'][i:i+batch_size]\n",
    "    \n",
    "    prompts=[]\n",
    "    answers=[]\n",
    "    for j in range(len(questions)):\n",
    "        answers.append(data['output'][i+j][0])\n",
    "        prompts.append(combine_data(questions[j],answers[j]))\n",
    "    # print(answers)\n",
    "    # print(f'Answers:\\n{answers}')\n",
    "    # Tokenize with padding for batch input\n",
    "    inputs = tokenizer(prompts, padding=padding, return_tensors=\"pt\", **add_special_tokens).to(model.device)\n",
    "\n",
    "    # output=generation(prompts, model_name, padding, padding_side, torch_dtype, special_tokens)\n",
    "   \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # Extract logits\n",
    "    logits = outputs.logits  # Shape: [batch_size, seq_len, vocab_size]\n",
    "    \n",
    "    \n",
    "    # Convert logits to log probabilities\n",
    "    log_probs = F.log_softmax(logits,dim=-1) # Shape: [batch_size, seq_len, vocab_size]\n",
    "    # print(f'log_probs:\\n{log_probs}')\n",
    "    # print(f'Shape of log_probs: {log_probs.shape}')\n",
    "\n",
    "    \n",
    "    # Identify the token IDs for the answer (without special tokens)\n",
    "    answer_token_ids = [tokenizer(a, add_special_tokens=False)[\"input_ids\"] for a in answers]\n",
    "    answer_tokens = []\n",
    "    answer_token_idxs=[]\n",
    "    \n",
    "    \n",
    "    for idx, (prompts, answer_tokens_ids) in enumerate(zip(prompts, answer_token_ids)):\n",
    "        # Extract token IDs for answer tokens in the concatenated input\n",
    "        # print(f'IDX:\\n{idx}')\n",
    "        # print(f'Prompts:\\n{prompts}')\n",
    "        # print(f'Answer_Token_Ids:\\n{answer_token_ids}')\n",
    "        # print(f'Input Ids:\\n{inputs[\"input_ids\"][idx]}')\n",
    "        answer_start_idx = (inputs[\"input_ids\"][idx] == answer_tokens_ids[0]).nonzero(as_tuple=True)[0][0].item()\n",
    "        answer_end_idx = answer_start_idx + len(answer_tokens_ids)\n",
    "        answer_tokens.append(inputs[\"input_ids\"][idx, answer_start_idx:answer_end_idx])\n",
    "        # print(f'Answer:\\n{tokenizer.decode(inputs[\"input_ids\"][idx, answer_start_idx:answer_end_idx], skip_special_tokens=True)}')\n",
    "        # answer_token_idxs.append(list(range(answer_start_idx, answer_end_idx)))\n",
    "        answer_token_idxs.append([answer_start_idx,answer_end_idx])\n",
    "\n",
    "    # Now, extract the log probs for the selected tokens (answer tokens)\n",
    "    for i, tokens in enumerate(answer_tokens):\n",
    "        # answer_positions = torch.tensor(answer_token_idxs[i], device=model.device)  # Convert to tensor\n",
    "        selected_log_probs = log_probs[i, answer_token_idxs[i][0]:answer_token_idxs[i][1]].gather(dim=-1, index=tokens.unsqueeze(-1)).squeeze(-1)\n",
    "        answer_log_probs.append(selected_log_probs.tolist())\n",
    "\n",
    "    # # Now, extract the log probs for the selected tokens (answer tokens)\n",
    "    # for i, tokens in enumerate(answer_tokens):\n",
    "    #     answer_positions = torch.tensor(answer_token_idxs[i], device=model.device)  # Convert to tensor\n",
    "    #     selected_log_probs = log_probs[i, answer_positions].gather(dim=-1, index=tokens.unsqueeze(-1)).squeeze(-1)\n",
    "    #     answer_log_probs.append(selected_log_probs.tolist())\n",
    "    \n",
    "#     # Print log probabilities for the answer tokens\n",
    "#     for idx, log_probs in enumerate(answer_log_probs):\n",
    "#         print(f\"Log probabilities for answer {idx}: {log_probs}\")\n",
    "    \n",
    "    \n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e2ba1b-4f7d-4f2e-83b5-3f63ab595705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1873b9ea-750b-4851-8f86-e3df2683581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.add_column(\"log_probs_teacher\", answer_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f520bf3d-5fdd-4510-83ec-227686010e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'log_probs', 'model_answer', 'GT_Answer', 'score', 'log_probs_teacher'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de929da0-bdfe-4dea-b360-80ba5c645be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"dataset.jsonl\", \"w\") as f:\n",
    "#     for row in data:\n",
    "#         f.write(json.dumps(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31acc17-87c1-4f96-a0b3-362afa874737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e083d87-6a3a-4a2d-89d6-1a2f770999a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "171\n",
      "0\n",
      "98\n",
      "97\n",
      "1\n",
      "194\n",
      "193\n",
      "2\n",
      "255\n",
      "254\n",
      "3\n",
      "126\n",
      "125\n",
      "4\n",
      "154\n",
      "153\n",
      "5\n",
      "340\n",
      "339\n",
      "6\n",
      "83\n",
      "82\n",
      "7\n",
      "174\n",
      "173\n",
      "8\n",
      "158\n",
      "157\n",
      "9\n",
      "245\n",
      "244\n",
      "10\n",
      "156\n",
      "155\n",
      "11\n",
      "196\n",
      "195\n",
      "12\n",
      "153\n",
      "152\n",
      "13\n",
      "207\n",
      "206\n",
      "14\n",
      "186\n",
      "185\n",
      "15\n",
      "199\n",
      "198\n",
      "16\n",
      "167\n",
      "166\n",
      "17\n",
      "150\n",
      "149\n",
      "18\n",
      "187\n",
      "186\n",
      "19\n",
      "149\n",
      "148\n",
      "20\n",
      "177\n",
      "176\n",
      "21\n",
      "126\n",
      "125\n",
      "22\n",
      "142\n",
      "141\n",
      "23\n",
      "165\n",
      "164\n",
      "24\n",
      "176\n",
      "175\n",
      "25\n",
      "168\n",
      "167\n",
      "26\n",
      "116\n",
      "115\n",
      "27\n",
      "284\n",
      "283\n",
      "28\n",
      "223\n",
      "222\n",
      "29\n",
      "94\n",
      "93\n",
      "30\n",
      "356\n",
      "355\n",
      "31\n",
      "225\n",
      "224\n",
      "32\n",
      "154\n",
      "153\n",
      "33\n",
      "129\n",
      "128\n",
      "34\n",
      "315\n",
      "314\n",
      "35\n",
      "127\n",
      "126\n",
      "36\n",
      "166\n",
      "165\n",
      "37\n",
      "211\n",
      "210\n",
      "38\n",
      "182\n",
      "181\n",
      "39\n",
      "143\n",
      "142\n",
      "40\n",
      "295\n",
      "294\n",
      "41\n",
      "141\n",
      "140\n",
      "42\n",
      "154\n",
      "153\n",
      "43\n",
      "239\n",
      "238\n",
      "44\n",
      "90\n",
      "89\n",
      "45\n",
      "131\n",
      "130\n",
      "46\n",
      "242\n",
      "241\n",
      "47\n",
      "160\n",
      "159\n",
      "48\n",
      "225\n",
      "224\n",
      "49\n",
      "326\n",
      "325\n",
      "50\n",
      "156\n",
      "155\n",
      "51\n",
      "196\n",
      "195\n",
      "52\n",
      "116\n",
      "115\n",
      "53\n",
      "196\n",
      "195\n",
      "54\n",
      "170\n",
      "169\n",
      "55\n",
      "171\n",
      "170\n",
      "56\n",
      "123\n",
      "122\n",
      "57\n",
      "225\n",
      "224\n",
      "58\n",
      "194\n",
      "193\n",
      "59\n",
      "135\n",
      "134\n",
      "60\n",
      "285\n",
      "284\n",
      "61\n",
      "256\n",
      "255\n",
      "62\n",
      "172\n",
      "171\n",
      "63\n",
      "202\n",
      "201\n",
      "64\n",
      "106\n",
      "105\n",
      "65\n",
      "214\n",
      "213\n",
      "66\n",
      "188\n",
      "187\n",
      "67\n",
      "140\n",
      "139\n",
      "68\n",
      "139\n",
      "138\n",
      "69\n",
      "90\n",
      "89\n",
      "70\n",
      "199\n",
      "198\n",
      "71\n",
      "136\n",
      "135\n",
      "72\n",
      "223\n",
      "222\n",
      "73\n",
      "138\n",
      "137\n",
      "74\n",
      "114\n",
      "113\n",
      "75\n",
      "204\n",
      "203\n",
      "76\n",
      "171\n",
      "170\n",
      "77\n",
      "197\n",
      "196\n",
      "78\n",
      "99\n",
      "98\n",
      "79\n",
      "165\n",
      "164\n",
      "80\n",
      "124\n",
      "123\n",
      "81\n",
      "206\n",
      "205\n",
      "82\n",
      "233\n",
      "232\n",
      "83\n",
      "213\n",
      "212\n",
      "84\n",
      "204\n",
      "203\n",
      "85\n",
      "130\n",
      "129\n",
      "86\n",
      "178\n",
      "177\n",
      "87\n",
      "130\n",
      "129\n",
      "88\n",
      "99\n",
      "98\n",
      "89\n",
      "130\n",
      "129\n",
      "90\n",
      "362\n",
      "361\n",
      "91\n",
      "256\n",
      "255\n",
      "92\n",
      "215\n",
      "214\n",
      "93\n",
      "184\n",
      "183\n",
      "94\n",
      "114\n",
      "113\n",
      "95\n",
      "158\n",
      "157\n",
      "96\n",
      "130\n",
      "129\n",
      "97\n",
      "123\n",
      "122\n",
      "98\n",
      "135\n",
      "134\n",
      "99\n",
      "184\n",
      "183\n",
      "100\n",
      "95\n",
      "94\n",
      "101\n",
      "143\n",
      "142\n",
      "102\n",
      "272\n",
      "271\n",
      "103\n",
      "269\n",
      "268\n",
      "104\n",
      "338\n",
      "337\n",
      "105\n",
      "125\n",
      "124\n",
      "106\n",
      "185\n",
      "184\n",
      "107\n",
      "170\n",
      "169\n",
      "108\n",
      "141\n",
      "140\n",
      "109\n",
      "202\n",
      "201\n",
      "110\n",
      "158\n",
      "157\n",
      "111\n",
      "244\n",
      "243\n",
      "112\n",
      "294\n",
      "293\n",
      "113\n",
      "193\n",
      "192\n",
      "114\n",
      "238\n",
      "237\n",
      "115\n",
      "142\n",
      "141\n",
      "116\n",
      "106\n",
      "105\n",
      "117\n",
      "199\n",
      "198\n",
      "118\n",
      "253\n",
      "252\n",
      "119\n",
      "135\n",
      "134\n",
      "120\n",
      "181\n",
      "180\n",
      "121\n",
      "114\n",
      "113\n",
      "122\n",
      "100\n",
      "99\n",
      "123\n",
      "134\n",
      "133\n",
      "124\n",
      "285\n",
      "284\n",
      "125\n",
      "124\n",
      "123\n",
      "126\n",
      "87\n",
      "86\n",
      "127\n",
      "94\n",
      "93\n",
      "128\n",
      "96\n",
      "95\n",
      "129\n",
      "186\n",
      "185\n",
      "130\n",
      "111\n",
      "110\n",
      "131\n",
      "114\n",
      "113\n",
      "132\n",
      "368\n",
      "367\n",
      "133\n",
      "156\n",
      "155\n",
      "134\n",
      "213\n",
      "212\n",
      "135\n",
      "171\n",
      "170\n",
      "136\n",
      "187\n",
      "186\n",
      "137\n",
      "278\n",
      "277\n",
      "138\n",
      "263\n",
      "262\n",
      "139\n",
      "169\n",
      "168\n",
      "140\n",
      "107\n",
      "106\n",
      "141\n",
      "251\n",
      "250\n",
      "142\n",
      "158\n",
      "159\n",
      "143\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs_teacher\u001b[39m\u001b[38;5;124m'\u001b[39m][i]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs_teacher\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(data.num_rows):\n",
    "    print(len(data['log_probs'][i][0]))\n",
    "    print(len(data['log_probs_teacher'][i]))\n",
    "    print(i)\n",
    "    assert len(data['log_probs'][i][0])-1==len(data['log_probs_teacher'][i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4ef996-8531-4837-b322-cda876158e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.016434656456112, -0.352039039134979, -0.313303917646408, -0.029853513464331002, -3.93382906622719e-05, -0.20064103603363, -0.00027926836628400003, -4.6491513785440475e-06, -0.003412378486245, -3.182837463100441e-05, -0.633067727088928, -0.007620431482791, -0.39467477798461903, -0.207727447152137, -0.026530675590038, 0.0, -0.8062194585800171, -0.012836328707635, -0.00030286493711100004, -0.018957853317260003, -0.44235873222351, -0.23087894916534402, -0.06290937215089701, -0.044039089232683, -0.081897713243961, -0.0021127776708450004, -0.00037222131504600003, -3.576278118089249e-07, -0.513729095458984, -1.017504215240478, -1.035511136054992, -0.004137171432375001, -1.311293544858926e-05, -0.000178440386662, -7.033323527139146e-06, -2.7298554414301183e-05, -1.430510451427835e-06, -0.43764889240264804, -0.005467580165714, -0.016074467450380003, -5.006777428206988e-06, -9.179073458653875e-06, -2.145764938177308e-06, -7.152531907195225e-06, -0.576463043689727, -0.005884229205548001, -0.840932965278625, -0.0017972521018230002, -0.20348392426967601, -1.430510451427835e-06, -0.005401777569204001, -0.051015265285968, -2.3722366677247923e-05, -0.001699671265669, -0.005132712423801001, -0.243351206183433, -4.2556810512905954e-05, -0.00026246439665500004, -4.1841583879431716e-05, -0.00016723664884900002, -0.654141426086425, -5.2808321925112984e-05, -0.9361624121665951, -3.576278118089249e-07, -0.038425210863351, -3.576278118089249e-07, -2.622600959512056e-06, -1.1682442163873931e-05, -0.292217969894409, -0.039372771978378004, -4.410734163684538e-06, 0.0, -2.145744110748637e-05, -2.694093564059585e-05, -0.000995259732007, -0.6590801477432251, -0.067146636545658, -0.40969184041023204, -0.461959242820739, -0.017731131985783, -0.227981358766555, -0.37814059853553705, -1.0132738680113102e-05, -0.078917622566223, -1.1801649634435302e-05, -0.00044300279114300003, -1.072883037522842e-06, -0.00017236177518400002, -1.4543427823809902e-05, -8.22540732769994e-06, -0.20864060521125702, -2.384183062531519e-06, -0.043184999376535006, -0.606793999671936, -0.0012524626217780002, -0.19966752827167503, -0.202669709920883, -2.622600959512056e-06, -1.192092213386786e-06, -6.079655122448457e-06, -1.6689160474925302e-05, 0.0, 0.0, -1.668928689468883e-06, -0.012510277330875001, -0.7532441020011901, -0.67979210615158, -0.003986033145338, -0.001249486114829, -3.337854650453664e-06, -0.062075845897197, -0.00138294394128, -6.508615479106086e-05, -3.242440288886428e-05, -1.7881377516459902e-06, -0.002483143471181, -0.00019727191829500002, -0.072429925203323, -0.68706077337265, -0.012515811249613, -0.045661490410566004, -0.07031853497028301, -0.029806189239025, -0.142693176865577, -1.192092213386786e-06, -0.28291350603103604, -0.019345885142683, -0.42880812287330605, -0.043005049228668005, -2.7418097943154862e-06, -0.000265086331637, -5.3285133617464467e-05, -2.145764938177308e-06, -1.026505947113037, -0.000493881292641, -0.00020239688456000001, -7.390948667307384e-06, -5.006777428206988e-06, -0.001712761935777, -1.192092824453538e-07, -7.152555099310121e-07, -1.2755313036905133e-05, -0.009662170894443, -0.0034507510717950002, -5.9364465414546444e-05, 0.0, -1.072883037522842e-06, -0.010342337191104, -5.960462772236497e-07, -0.000394862407119, -0.20345444977283403, -5.960462772236497e-07, 0.0, 0.0, 0.0, -2.3841855067985288e-07, -0.000261749344645, -8.344646857949556e-07]\n"
     ]
    }
   ],
   "source": [
    "print(data['log_probs'][i][0]) # vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125005b0-7464-40f9-a6b5-38c655e3089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-26.625, -18.5, -16.25, -19.25, -15.0, -24.125, -25.25, -23.75, -29.375, -26.125, -22.5, -29.875, -16.0, -13.0, -24.5, -17.375, -20.375, -18.875, -16.75, -12.75, -14.8125, -15.9375, -21.125, -16.0, -18.125, -17.375, -27.875, -22.0, -31.875, -20.0, -24.125, -17.5, -19.625, -31.375, -20.75, -26.875, -23.75, -19.375, -17.75, -22.625, -20.0, -32.0, -23.625, -21.875, -28.25, -17.0, -22.75, -15.5, -22.5, -21.5, -13.375, -18.5, -18.125, -20.5, -17.75, -20.25, -20.0, -24.625, -26.5, -19.0, -27.0, -24.5, -28.5, -26.625, -20.375, -19.125, -31.875, -18.5, -23.25, -27.0, -25.25, -23.625, -20.75, -29.875, -19.875, -29.125, -27.875, -22.875, -17.875, -18.5, -18.875, -14.4375, -25.5, -19.0, -19.5, -21.625, -28.875, -26.0, -25.375, -24.5, -10.625, -23.0, -21.875, -14.5625, -29.125, -24.5, -19.625, -21.125, -14.75, -30.125, -19.25, -22.25, -24.5, -32.5, -19.125, -28.5, -26.125, -18.125, -21.625, -23.5, -25.375, -17.0, -18.875, -18.75, -26.375, -19.875, -19.625, -25.375, -14.6875, -24.0, -22.125, -15.4375, -21.125, -21.25, -22.625, -27.25, -21.375, -18.875, -15.5625, -21.375, -18.125, -23.0, -26.75, -22.875, -22.375, -23.625, -31.625, -31.375, -23.875, -24.0, -18.0, -28.75, -16.75, -25.5, -30.625, -21.0, -23.0, -18.875, -27.0, -29.0, -21.5, -27.5, -33.25, -29.625, -25.75, -20.625, -22.25, -28.75, -34.75]\n"
     ]
    }
   ],
   "source": [
    "print(data['log_probs_teacher'][i]) # HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12882c13-d4dc-4ac3-a43a-d114d2d5cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9b335c-2789-4e0d-9432-91172fbd568b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836996557122539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.016434656456112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49987ad-b805-4799-aea7-22bbb0d96682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
