{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53d4890-ce60-43d0-b45d-142cf23a39b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing conda version miniforge3-24.7.1\n",
      "Loading conda version miniforge3-24.7.1\n"
     ]
    }
   ],
   "source": [
    "!source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a94d53-67a4-472a-805a-bb794d1f8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "# cache_dir =  \"/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "# os.environ['HF_HOME']=cache_dir\n",
    "# os.environ['HF_HUB_CACHE']=cache_dir+'/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e98810f-66cc-4bdf-8d0c-25bcee1ca525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from vllm.inputs import TokensPrompt\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5664f354-d52f-4760-b461-1a8ead0c385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'input_ids'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data_path = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/datasets/gsm8k/tokenized/Llama-3.2-1B-Instruct/test/0-shot'\n",
    "# data_path= \"../datasets/gsm8k/tokenized/Llama-3.2-1B-Instruct/\"\n",
    "# split='test'\n",
    "# data=load_from_disk(data_path+split+'/0-shot')\n",
    "data=load_from_disk(data_path)\n",
    "# data = load_from_disk(f\"{data_path}/tokenized/LLaMA8B-Instruct/{split}/0-shot/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b8ec1c-1fd8-4c54-9126-48c2a920ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# # model_name= \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# # model_name='/datasets/ai/llama3/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/'\n",
    "# model_name='meta-llama/Llama-3.2-3B-Instruct'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3619403d-97d9-495e-ba67-8f689767c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68afe37c-2790-4816-97dc-67d2e0947dcd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cache_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownload_dir\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mcache_dir\u001b[49m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_model_len\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m LLM(\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_name,  \n\u001b[1;32m      8\u001b[0m         tensor_parallel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     12\u001b[0m ) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'cache_dir' is not defined"
     ]
    }
   ],
   "source": [
    "kwargs={\n",
    "    'download_dir':cache_dir,\n",
    "    'max_model_len': 2000\n",
    "}\n",
    "\n",
    "model = LLM(\n",
    "        model=model_name,  \n",
    "        tensor_parallel_size=1,\n",
    "        trust_remote_code=True,\n",
    "        # gpu_memory_utilization=0.97,  # Increase this value\n",
    "    **kwargs\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3d5da6-71a5-4648-adff-fa593703f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_strings =  ['<|eot_id|>', '<|start_header_id|>user<|end_header_id|>', 'Q:', '</s>', '<|im_end|>', 'the']\n",
    "\n",
    "\n",
    "sampling_params = SamplingParams(n=1,\n",
    "                                 temperature=0,\n",
    "                                 max_tokens=500,\n",
    "                                 stop=stop_strings,\n",
    "                                 # logprobs=2,\n",
    "                                 best_of=1,\n",
    "                                 presence_penalty=0,\n",
    "                                 top_p=1,\n",
    "                                 top_k=1\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57406379-b68a-4792-b4c7-68672d73c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# task='gec'\n",
    "# task_prompt_path=f'../prompts/{task}.json'\n",
    "# with open(task_prompt_path) as fp:\n",
    "#     task_prompt = json.load(fp)\n",
    "# task_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2e85fb-e2e7-4a58-b434-ada722ce989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt=[]\n",
    "# for i in range(len(data)):\n",
    "# # for i in range(26,28):\n",
    "#     chat=[\n",
    "#         {\n",
    "#             \"role\":\"system\",\n",
    "#             \"content\":task_prompt['system_msg'],\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\":\"user\",\n",
    "#             \"content\":task_prompt['user_msg'].format(instruction=task_prompt['task_prompt'], question=data[i]['input'])\n",
    "#         }\n",
    "#     ]\n",
    "#     prompt.append(tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True))\n",
    "# # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68e24bc-f1f4-49b2-8cd2-b843d1b4c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompt[332])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4e7a5ce-ab58-4f06-832b-1d70f8b13231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, est. speed input: 2195.41 toks/s, output: 142.11 toks/s]\n"
     ]
    }
   ],
   "source": [
    "all_outputs = model.generate(data['input_ids'][0], sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f526fb3d-c950-438f-a433-a6d5e32a83ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionOutput(index=0, text='To find out how much Janet makes at ', token_ids=array('l', [1271, 1505, 704, 1268, 1790, 54765, 3727, 520, 279]), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=the)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a95c4c7c-4bae-40b5-9bc1-4eb8c7aa8ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find out how much Janet makes at '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbf2b352-f312-4f0e-a25d-8a49b87739f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find out how much Janet makes at the'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(all_outputs[0].outputs[0].token_ids, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f674e59-53ee-4486-a03e-3cf808930e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find out how much Janet makes at the'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(all_outputs[0].outputs[0].token_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d3f392c-7db0-4a55-984c-76e7b309e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RequestOutput(request_id=1, prompt=None, prompt_token_ids=[128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1187, 13806, 220, 2366, 20, 271, 128009, 128006, 882, 128007, 271, 22818, 279, 2768, 3575, 11, 2944, 323, 3041, 264, 1620, 4320, 311, 279, 3575, 627, 32298, 25, 54765, 753, 78878, 11203, 220, 845, 19335, 824, 1938, 13, 3005, 50777, 2380, 369, 17954, 1475, 6693, 323, 293, 2094, 55404, 1354, 369, 1077, 4885, 1475, 1938, 449, 3116, 13, 3005, 31878, 279, 27410, 520, 279, 20957, 6, 3157, 7446, 369, 400, 17, 824, 7878, 37085, 19151, 13, 2650, 1790, 304, 11441, 1587, 1364, 1304, 1475, 1938, 520, 279, 20957, 6, 3157, 5380, 7927, 2077, 1288, 842, 449, 330, 791, 1620, 4320, 374, 510, 9399, 19727, 1405, 510, 9399, 60, 374, 279, 2077, 311, 279, 3575, 13, 128009, 128006, 78191, 128007, 271], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='To find out how much Janet makes at ', token_ids=array('l', [1271, 1505, 704, 1268, 1790, 54765, 3727, 520, 279]), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=the)], finished=True, metrics=RequestMetrics(arrival_time=1748098541.8771443, last_token_time=1748098541.8771443, first_scheduled_time=1748098541.8791618, first_token_time=1748098541.8899493, time_in_queue=0.002017498016357422, finished_time=1748098541.937178, scheduler_time=0.0005465048598125577, model_forward_time=None, model_execute_time=None), lora_request=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac86311-5b69-4563-af68-71852b768185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Write a solution to the following problem and make sure that it passes the tests:\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      " \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      " given threshold.\n",
      " >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      " False\n",
      " >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      " True\n",
      " \"\"\"\n",
      "\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here is the completed function:\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      " \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      " given threshold.\n",
      " >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      " False\n",
      " >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      " True\n",
      " \"\"\"\n"
     ]
    }
   ],
   "source": [
    "print('<|start_header_id|>user<|end_header_id|>\\n\\nWrite a solution to the following problem and make sure that it passes the tests:\\n```python\\nfrom typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n given threshold.\\n >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n False\\n >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n True\\n \\\"\\\"\\\"\\n\\n```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nHere is the completed function:\\n```python\\nfrom typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n given threshold.\\n >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n False\\n >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n True\\n \\\"\\\"\\\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5d05d-c0e8-4dc8-bcad-5a72c9a7202b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
