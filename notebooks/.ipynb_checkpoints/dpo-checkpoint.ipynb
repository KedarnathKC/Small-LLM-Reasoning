{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2950fab0-b612-42f5-bd72-368d64a2c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME']=cache_dir\n",
    "os.environ['HF_HUB_CACHE']=cache_dir+'/hub'\n",
    "hf_token=os.getenv('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f801af0f-6703-440c-bf59-ee0515ee9cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from datasets import load_from_disk, Dataset, load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b1752-a43b-4add-bfba-6ab98a6f11a8",
   "metadata": {},
   "source": [
    "### Preparing data in preference format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451e3c65-7d1b-4f9a-a2ef-e35f8ecaaddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_from_disk('../datasets/gsm8k/feedback/')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c5bf74-88cd-445b-8caf-e025c0a7c0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'token_ids', 'log_probs', 'all_returned_log_probs', 'model_answer', 'GT_Answer', 'score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_data_path = '../outputs/exp-2.0.3/eval_1/generated_outputs.json'\n",
    "teacher_data = load_dataset('json',data_files=teacher_data_path)['train']\n",
    "teacher_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303f295c-5ad3-4586-8b58-48a04e7b6841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'gt_reasoning', 'gt_answer', 'student_token_ids', 'student_reasoning', 'student_answer', 'student_correctness', 'student_log_probs', 'teacher_log_probs', 'teacher_correctness'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data_path='../outputs/exp-2.1.1/eval_1/logprobs1.json'\n",
    "student_data=load_dataset('json', data_files=student_data_path)['train']\n",
    "student_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc252c4-816b-4538-9848-d2c3c2e33c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_data_path='../outputs/exp-2.1.1/eval_1/logprobs.json'\n",
    "# student_data1=load_dataset('json', data_files=student_data_path)['train']\n",
    "# student_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48095737-2c65-47de-9a9f-0650a36ec15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompt_func(questions):\n",
    "    final_prompts=[]\n",
    "    for question in questions:\n",
    "        prompt = f'<|start_header_id|>user<|end_header_id|>\\n\\nGiven the following problem, reason and give a final answer to the problem.\\nProblem: {question}\\nYour response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'\n",
    "        final_prompts.append(prompt)\n",
    "    return final_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30632b4f-db60-44bf-a0ff-18db16e35442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>user<|end_header_id|>\\n\\nGiven the following problem, reason and give a final answer to the problem.\\nProblem: A box is 8 inches in height, 10 inches in width, and 12 inches in length. A wooden building block is 3 inches in height, 2 inches in width, and 4 inches in length. How many building blocks can fit into the box?\\nYour response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt= formatting_prompt_func(data['question'])\n",
    "prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8b939d-0f56-4b95-86f6-31ff91f56146",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen= [tr_output[0] for tr_output in teacher_data['output']] \n",
    "rejected= student_data['student_reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990e25a9-282f-410a-a81c-60de3bc988da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(teacher_log_prob):\n",
    "    teacher_logprob=[]\n",
    "    for i in range(len(teacher_log_prob)):\n",
    "        teacher_log_probs=np.array(teacher_log_prob[i])\n",
    "        teacher_logprob.append(np.mean(teacher_log_probs))\n",
    "    teacher_prob=np.exp(teacher_logprob)\n",
    "    return teacher_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca12e52-b56a-4931-a09d-5b3ac972629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704129501564671\n",
      "0.193618609447841\n"
     ]
    }
   ],
   "source": [
    "teacher_prob= get_prob(student_data['teacher_log_probs'])\n",
    "print(np.max(teacher_prob))\n",
    "print(np.min(teacher_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ffac50b-9b2d-4e36-92a6-981a4b85c5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'tr_answer', 'stu_answer', 'tr_prob', 'tr_score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'prompt': prompt,\n",
    "    'chosen': chosen,\n",
    "    'rejected': rejected,\n",
    "    'tr_answer': teacher_data['model_answer'],\n",
    "    'stu_answer': student_data['student_answer'],\n",
    "    'tr_prob':teacher_prob,\n",
    "    'tr_score': teacher_data['score']\n",
    "    }\n",
    "    \n",
    "preference_data= Dataset.from_dict(new_data)\n",
    "preference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6949bce2-2a13-490e-8e12-2a9f0f8473f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1000/1000 [00:00<00:00, 103198.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'tr_answer', 'stu_answer', 'tr_prob', 'tr_score'],\n",
       "    num_rows: 951\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_data= preference_data.filter(lambda x: x['tr_score']==1)\n",
    "preference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c9fb19-f54b-40c7-a24f-07fe61d7bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 951/951 [00:00<00:00, 51549.32 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'tr_answer', 'stu_answer', 'tr_prob', 'tr_score'],\n",
       "    num_rows: 89\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_data_wenlong= preference_data.filter(lambda x: x['tr_prob']<=0.6)\n",
    "preference_data_wenlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cae246-123b-45c5-baa4-d8199ebd47d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 951/951 [00:00<00:00, 61048.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'tr_answer', 'stu_answer', 'tr_prob', 'tr_score'],\n",
       "    num_rows: 71\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_data_arafat= preference_data.filter(lambda x: x['tr_answer']!=x['stu_answer'])\n",
    "preference_data_arafat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b00cf0a0-b2da-438d-a145-dc45bbc98bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine how much Leila and her friends will save by choosing the first car rental option over the second, we need to calculate the total cost of each option for their trip.\\n\\nThe trip is 150 kilometers long each way, so the total distance covered in a day (to and from the destination) is 150 km * 2 = 300 km.\\n\\nThe first option costs $50 a day, excluding gasoline. To calculate the cost of gasoline for this option:\\n- The total distance of the trip is 300 km.\\n- A liter of gasoline covers 15 km, so the amount of gasoline needed for 300 km is 300 km / 15 km per liter = 20 liters.\\n- The cost of gasoline is $0.90 per liter, so the total cost for gasoline is 20 liters * $0.90 per liter = $18.\\nTherefore, the total cost for the first option is $50 (rental) + $18 (gasoline) = $68.\\n\\nThe second option costs $90 a day, including gasoline. There's no need to calculate the gasoline cost separately since it's already included in the daily rate.\\n\\nTo find out how much they will save by choosing the first option over the second:\\nSavings = Cost of the second option - Cost of the first option\\nSavings = $90 - $68\\nSavings = $22\\n\\nThe final answer is $22\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_data_wenlong['chosen'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf630d39-1812-4fac-a9d9-51fe310be4b7",
   "metadata": {},
   "source": [
    "## DPO Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9d3b47-112c-456e-ba53-ed94b578be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dpo.py\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b62f59-3314-4b5a-9384-44361d1f3915",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "Extracting prompt in train dataset: 100%|██████████| 89/89 [00:00<00:00, 7162.18 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 89/89 [00:00<00:00, 9886.20 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 89/89 [00:00<00:00, 865.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_name='meta-llama/Llama-3.2-3B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=hf_token, \n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype='bfloat16',\n",
    "    token=hf_token, \n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    output_dir=\"Wenlong\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-6, # Default 1e-6\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='cosine',\n",
    "    save_strategy=\"epoch\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=100\n",
    ")\n",
    "trainer = DPOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=preference_data_wenlong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81440a-59be-4f5a-b037-0c9e11d730bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/25 00:57 < 02:43, 0.10 it/s, Epoch 1.35/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd41dee-3ec1-4f7b-82b0-5e3ceca6693f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64e7d5-10c3-49be-ab92-aa030222ce9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1f0f7-3479-4567-9402-4ee8ffc9190d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf5337-0a56-44e8-acfd-1a94ce5fca95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddf151-6a3f-42be-b8eb-84f7acd21bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d83e2-0d27-49bc-bdb7-4baef8e73a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb3bfb-4c24-4802-9780-7b9215e390c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e471d-79f7-4d91-ab0e-ad67b165ec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cecb6-2aee-4da5-a155-3a3c089336f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d693e-7f0e-4d0d-bbb8-d4d3efaacb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d007284-e988-4c83-be0d-adb099e559ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fd5e9-c7c6-4b53-a1d9-72b6f1a9c209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22975391-b8c2-4fbb-b05a-da86165bbf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a05a35-4993-48b8-b98a-e5ea098f2c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ac35c-a141-4493-93bc-04b92a539208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffb4b0-b5a1-44ac-91ef-1064ea47f453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6554ac-7e93-47f8-9ffa-8525a2583fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ff627-ec43-48c1-9303-453820d82a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
