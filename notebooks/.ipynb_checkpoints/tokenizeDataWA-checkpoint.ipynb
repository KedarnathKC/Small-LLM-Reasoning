{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91722a3d-e845-4788-aa50-80656fcfafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME']=cache_dir\n",
    "os.environ['HF_HUB_CACHE']=cache_dir+'/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1d64fb-6bcb-4738-be5c-f1a299a1e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5b53c2-9661-42c4-b0b6-725c8f6b174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "hf_token = os.getenv(\"hf_token\")\n",
    "\n",
    "model_name= \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d820cd-28dd-43c2-b5de-3ce355b10bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(ex, prompt_template, task_prompt, few_shot, few_shot_examples, n=3):\n",
    "    prompt=[\n",
    "        {\n",
    "            'role':'system',\n",
    "            'content':prompt_template['system_msg']\n",
    "        }\n",
    "    ]\n",
    "    if few_shot:\n",
    "        for idx in range(n):\n",
    "            prompt.extend([\n",
    "                {\n",
    "                    'role':'user',\n",
    "                    'content':prompt_template['user_msg'].format(instruction=task_prompt, question=few_shot_examples[idx]['input'])\n",
    "                },\n",
    "                {\n",
    "                    'role':'assistant',\n",
    "                    'content':prompt_template['assistant_msg'].format(response=few_shot_examples[idx]['reference'], rationale=few_shot_examples[idx]['rationale'])\n",
    "                }\n",
    "                                                                      \n",
    "            ])\n",
    "        \n",
    "    prompt.append(\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':prompt_template['user_msg'].format(instruction=task_prompt, question=ex)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def tokenize_function(example,input_column, prompt_template, task_prompt, few_shot, few_shot_examples, n=3):\n",
    "    prompt= get_prompt(example[input_column], prompt_template, task_prompt, few_shot, few_shot_examples, n)\n",
    "    prompt= tokenizer.apply_chat_template(prompt,  tokenize= False, add_generation_prompt=True)\n",
    "    return {'input_ids': {'prompt_token_ids':tokenizer(prompt, add_special_tokens=False)['input_ids']}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6dd5192-5f94-4aee-b4d5-5b4f4badfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(task_name, split, input_column, prompt_template, task_prompt, few_shot, few_shot_examples, n):\n",
    "    data_path= f'../datasets/{task_name}'\n",
    "    data = load_from_disk(f\"{data_path}/{split}/\")\n",
    "    tokenized_dataset = data.map(lambda x: tokenize_function(x, input_column, prompt_template, task_prompt, few_shot, few_shot_examples, n), batched=False)\n",
    "    output_path=f\"{data_path}/tokenized/LLaMA8B-Instruct/{split}/{n}-shot/\"\n",
    "    print(output_path)\n",
    "    tokenized_dataset.save_to_disk(output_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39494ecc-0ca0-4442-819a-8f7d88a29f9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../prompts/gec.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgec\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     task_prompt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../prompts/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m      5\u001b[0m         task_prompt \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n\u001b[1;32m      6\u001b[0m     prompt_template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../prompts/llama.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../prompts/gec.json'"
     ]
    }
   ],
   "source": [
    "input_column='text'\n",
    "for task in ['gec']:\n",
    "    task_prompt_path=f'../prompts/{task}.json'\n",
    "    with open(task_prompt_path) as fp:\n",
    "        task_prompt = json.load(fp)\n",
    "    prompt_template_path='../prompts/llama.json'\n",
    "    with open(prompt_template_path) as fp:\n",
    "        prompt_template = json.load(fp)\n",
    "    for split in ['feedback']:\n",
    "        for few_shot in [False]:\n",
    "            if few_shot:\n",
    "                for n in [3]:\n",
    "                    tokenize_data(task, split, input_column, prompt_template, task_prompt['task_prompt'], few_shot, task_prompt['few_shot'], n)\n",
    "            else:\n",
    "                tokenize_data(task, split, input_column, prompt_template, task_prompt['task_prompt'], few_shot, task_prompt['few_shot'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f7af5-1e22-4ecb-9577-3f8624a795cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47677021-bbda-4e8b-9a7f-66fde53fd2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98675075-a7bf-4946-aae7-e454123c7041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9033c649-0c4d-476c-bb9f-a6f65b11df46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "    num_rows: 700\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "task='neutralization'\n",
    "input_column='input'\n",
    "data_path= f'../datasets/{task}'\n",
    "split='val'\n",
    "data = load_from_disk(f\"{data_path}/{split}/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fe52a2-f505-4ca0-b553-525e73029412",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt_path=f'../prompts/{task}.json'\n",
    "with open(task_prompt_path) as fp:\n",
    "    task_prompt = json.load(fp)\n",
    "prompt_template_path='../prompts/llama.json'\n",
    "with open(prompt_template_path) as fp:\n",
    "    prompt_template = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8624078e-b583-4bd8-ac4b-d6068e5c1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The neutralized text is  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template['assistant_msg'].format(response='0',rationale='0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9834196-ea7d-4a93-9d2c-b603efc9dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column='input'\n",
    "few_shot=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75eb4c7-5d44-4514-a801-7bca8e6a8003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert in removing subjective biases in texts.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Instruction:\\nGiven an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\\n1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\\n2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\\n3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\\n\\nYour response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\\n\\nInput:\\nin addition to sponsoring palestinian terror attacks against israel (often through jordanian territory, much to king hussein\\'s chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.\\n\\n'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=get_prompt(data['input'][0], prompt_template, task_prompt['task_prompt'], few_shot, task_prompt['few_shot'], n=2)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39e2f5c8-432b-495a-beb3-d7bd98ec1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an expert in removing subjective biases in texts.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "in addition to sponsoring palestinian terror attacks against israel (often through jordanian territory, much to king hussein's chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=tokenizer.apply_chat_template(prompt,  tokenize= False, add_generation_prompt=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bffd25b-da34-495b-b8fa-3a30ca70f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an expert in removing subjective biases in texts.user\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "gender-neutral pronouns used in ancient englishassistant\n",
      "\n",
      "The word ancient should be replaced by middle because middle more accurately specifies the historical period of the English language being referred to, aligning with the target sentenceâ€™s neutral and precise tone. The neutralized text is  gender-neutral pronouns used in middle englishuser\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "based on the motorola 68k series of microprocessors, the machine sported a custom chipset with advanced graphics and sound capabilities, and a sophisticated pre-emptive multitasking operating system (now known as amigaos).assistant\n",
      "\n",
      "The word sophisticated should be deleted because it introduces a subjective evaluation. Neutralizing the sentence requires removing such evaluative language to maintain an objective tone. The neutralized text is  based on the motorola 68k series of microprocessors, the machine sported a custom chipset with advanced graphics and sound capabilities, and a pre-emptive multitasking operating system (now known as amigaos).user\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "in addition to sponsoring palestinian terror attacks against israel (often through jordanian territory, much to king hussein's chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.assistant\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=tokenizer.decode(tokenizer(prompt)['input_ids'],skip_special_tokens=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f17ac03b-febf-44eb-a813-8b741a0a5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "task='neutralization'\n",
    "task_prompt_path=f'../prompts/{task}.json'\n",
    "with open(task_prompt_path) as fp:\n",
    "    task_prompt = json.load(fp)\n",
    "prompt_template_path='../prompts/llama.json'\n",
    "with open(prompt_template_path) as fp:\n",
    "    prompt_template = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2661ce8-690f-41ca-8e2a-59a3bcb9b35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "    num_rows: 700\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "task='neutralization'\n",
    "input_column='input'\n",
    "data_path= f'../datasets/{task}'\n",
    "split='val'\n",
    "data = load_from_disk(f\"{data_path}/{split}/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c725e98e-e15a-4e8e-9aa6-683d9fe746a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func_neutralization(example):\n",
    "    with open('../prompts/neutralization.json') as fp:\n",
    "        task_prompt = json.load(fp)\n",
    "    system_msg= f'<|start_header_id|>system<|end_header_id|>\\n\\n{task_prompt['system_msg']}<|eot_id|>'\n",
    "    user_msg= f'<|start_header_id|>user<|end_header_id|>\\n\\n{task_prompt['user_msg'].format(instruction=task_prompt['task_prompt'], question=example['input'])}<|eot_id|>'\n",
    "    rationale= example['rationale'] if 'rationale' in example else ''\n",
    "    assistant_msg=f'<|start_header_id|>assistant<|end_header_id|>\\n\\n{task_prompt['assistant_msg'].format(rationale=rationale, response=example['edits'])}<|eot_id|>'\n",
    "    \n",
    "    text= system_msg + user_msg + assistant_msg\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0060da43-585d-4cc8-a0ef-bd5422ddf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are an expert in removing subjective biases in texts.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "in addition to sponsoring palestinian terror attacks against israel (often through jordanian territory, much to king hussein's chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.\n",
      "\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      " The neutralized text is  in addition to sponsoring palestinian attacks against israel (often through jordanian territory, much to king hussein's chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(formatting_prompts_func_neutralization(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd2fa44b-ffa2-450f-bab6-ce88d608cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an expert in removing subjective biases in texts.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Instruction:\n",
      "Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\n",
      "1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\n",
      "2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\n",
      "3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\n",
      "\n",
      "Your response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.\n",
      "\n",
      "Input:\n",
      "in addition to sponsoring palestinian terror attacks against israel (often through jordanian territory, much to king hussein's chagrin), syria also began shelling of israeli civilian communities in north-eastern galilee, from gun emplacements on the syrian-controlled golan heights.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=tokenizer.apply_chat_template(prompt,  tokenize= False, add_generation_prompt=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15901963-412c-4bfb-b2d4-6d8a95ac0247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
