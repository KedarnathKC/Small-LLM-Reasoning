{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6250c7-7ab8-4609-a21b-c2116bf381eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME']=cache_dir\n",
    "os.environ['HF_HUB_CACHE']=cache_dir+'/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4816db-7562-42d9-8a72-9384bc329a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, load_dataset\n",
    "# from small_llm_reasoning.generation.transformers_generation import generation\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f860d8-c3e7-4aae-9044-d55bfed5efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:00, 1984.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'token_ids', 'log_probs', 'all_returned_log_probs', 'model_answer', 'GT_Answer', 'score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('json',data_files='/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/outputs/exp-2.0.1/eval_1/generated_outputs.json')['train']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924fb1d9-dbb2-442b-aaf9-074e3fb9fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc63ba-3148-4c29-92c0-f746dd4fd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.num_rows):\n",
    "    assert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fcaae9-c95e-4da4-868b-39457cada8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "padding='longest'\n",
    "padding_side=None\n",
    "special_tokens=False\n",
    "torch_dtype='bfloat16'\n",
    "hf_token=os.getenv('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e99ea03-33b3-4f8a-9fed-699ee938d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache/models--meta-llama--Llama-3.2-3B-Instruct/.no_exist/0cb88a4f764b7a12671c53f0838cd831a0843b95/adapter_config.json'\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        token=hf_token, \n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch_dtype,\n",
    "    token=hf_token, \n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "if padding_side:\n",
    "        tokenizer.padding_side = padding_side\n",
    "add_special_tokens = {\"add_special_tokens\": special_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "922e81a1-728f-4612-83d2-ec5efc79a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(q,a):\n",
    "    return q+a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a45dd0a-07aa-444f-9f06-849a71742276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=tokenizer(data['output'][143][0],return_tensors=\"pt\", **add_special_tokens)\n",
    "output['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45e16323-c594-42e2-a684-847385a70ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['log_probs'][143][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bd533f-cecc-4f07-ab53-135b075b3751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:15<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size=1\n",
    "answer_log_probs = []\n",
    "for i in tqdm(range(0,data.num_rows,batch_size)):\n",
    "    questions=data['input'][i:i+batch_size]\n",
    "    \n",
    "    prompts=[]\n",
    "    answers=[]\n",
    "    for j in range(len(questions)):\n",
    "        answers.append(data['output'][i+j][0])\n",
    "        prompts.append(combine_data(questions[j],answers[j]))\n",
    "    # print(answers)\n",
    "    # print(f'Answers:\\n{answers}')\n",
    "    # Tokenize with padding for batch input\n",
    "    inputs = tokenizer(prompts, padding=padding, return_tensors=\"pt\", **add_special_tokens).to(model.device)\n",
    "\n",
    "    # output=generation(prompts, model_name, padding, padding_side, torch_dtype, special_tokens)\n",
    "   \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # Extract logits\n",
    "    logits = outputs.logits  # Shape: [batch_size, seq_len, vocab_size]\n",
    "    \n",
    "    \n",
    "    # Convert logits to log probabilities\n",
    "    log_probs = F.log_softmax(logits,dim=-1) # Shape: [batch_size, seq_len, vocab_size]\n",
    "    # print(f'log_probs:\\n{log_probs}')\n",
    "    # print(f'Shape of log_probs: {log_probs.shape}')\n",
    "\n",
    "    \n",
    "    # Identify the token IDs for the answer (without special tokens)\n",
    "    answer_token_ids = [tokenizer(a, add_special_tokens=False)[\"input_ids\"] for a in answers]\n",
    "    answer_tokens = []\n",
    "    answer_token_idxs=[]\n",
    "    \n",
    "    \n",
    "    for idx, (prompts, answer_tokens_ids) in enumerate(zip(prompts, answer_token_ids)):\n",
    "        # Extract token IDs for answer tokens in the concatenated input\n",
    "        # print(f'IDX:\\n{idx}')\n",
    "        # print(f'Prompts:\\n{prompts}')\n",
    "        # print(f'Answer_Token_Ids:\\n{answer_token_ids}')\n",
    "        # print(f'Input Ids:\\n{inputs[\"input_ids\"][idx]}')\n",
    "        answer_start_idx = (inputs[\"input_ids\"][idx] == answer_tokens_ids[0]).nonzero(as_tuple=True)[0][0].item()\n",
    "        answer_end_idx = answer_start_idx + len(answer_tokens_ids)\n",
    "        answer_tokens.append(inputs[\"input_ids\"][idx, answer_start_idx:answer_end_idx])\n",
    "        # print(f'Answer:\\n{tokenizer.decode(inputs[\"input_ids\"][idx, answer_start_idx:answer_end_idx], skip_special_tokens=True)}')\n",
    "        # answer_token_idxs.append(list(range(answer_start_idx, answer_end_idx)))\n",
    "        answer_token_idxs.append([answer_start_idx,answer_end_idx])\n",
    "\n",
    "    # Now, extract the log probs for the selected tokens (answer tokens)\n",
    "    for i, tokens in enumerate(answer_tokens):\n",
    "        # answer_positions = torch.tensor(answer_token_idxs[i], device=model.device)  # Convert to tensor\n",
    "        selected_log_probs = log_probs[i, answer_token_idxs[i][0]:answer_token_idxs[i][1]].gather(dim=-1, index=tokens.unsqueeze(-1)).squeeze(-1)\n",
    "        answer_log_probs.append(selected_log_probs.tolist())\n",
    "\n",
    "    # # Now, extract the log probs for the selected tokens (answer tokens)\n",
    "    # for i, tokens in enumerate(answer_tokens):\n",
    "    #     answer_positions = torch.tensor(answer_token_idxs[i], device=model.device)  # Convert to tensor\n",
    "    #     selected_log_probs = log_probs[i, answer_positions].gather(dim=-1, index=tokens.unsqueeze(-1)).squeeze(-1)\n",
    "    #     answer_log_probs.append(selected_log_probs.tolist())\n",
    "    \n",
    "#     # Print log probabilities for the answer tokens\n",
    "#     for idx, log_probs in enumerate(answer_log_probs):\n",
    "#         print(f\"Log probabilities for answer {idx}: {log_probs}\")\n",
    "    \n",
    "    \n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e2ba1b-4f7d-4f2e-83b5-3f63ab595705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1873b9ea-750b-4851-8f86-e3df2683581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.add_column(\"log_probs_teacher\", answer_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f520bf3d-5fdd-4510-83ec-227686010e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'log_probs', 'model_answer', 'GT_Answer', 'score', 'log_probs_teacher'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de929da0-bdfe-4dea-b360-80ba5c645be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"dataset.jsonl\", \"w\") as f:\n",
    "#     for row in data:\n",
    "#         f.write(json.dumps(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31acc17-87c1-4f96-a0b3-362afa874737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e083d87-6a3a-4a2d-89d6-1a2f770999a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "171\n",
      "0\n",
      "98\n",
      "97\n",
      "1\n",
      "194\n",
      "193\n",
      "2\n",
      "255\n",
      "254\n",
      "3\n",
      "126\n",
      "125\n",
      "4\n",
      "154\n",
      "153\n",
      "5\n",
      "340\n",
      "339\n",
      "6\n",
      "83\n",
      "82\n",
      "7\n",
      "174\n",
      "173\n",
      "8\n",
      "158\n",
      "157\n",
      "9\n",
      "245\n",
      "244\n",
      "10\n",
      "156\n",
      "155\n",
      "11\n",
      "196\n",
      "195\n",
      "12\n",
      "153\n",
      "152\n",
      "13\n",
      "207\n",
      "206\n",
      "14\n",
      "186\n",
      "185\n",
      "15\n",
      "199\n",
      "198\n",
      "16\n",
      "167\n",
      "166\n",
      "17\n",
      "150\n",
      "149\n",
      "18\n",
      "187\n",
      "186\n",
      "19\n",
      "149\n",
      "148\n",
      "20\n",
      "177\n",
      "176\n",
      "21\n",
      "126\n",
      "125\n",
      "22\n",
      "142\n",
      "141\n",
      "23\n",
      "165\n",
      "164\n",
      "24\n",
      "176\n",
      "175\n",
      "25\n",
      "168\n",
      "167\n",
      "26\n",
      "116\n",
      "115\n",
      "27\n",
      "284\n",
      "283\n",
      "28\n",
      "223\n",
      "222\n",
      "29\n",
      "94\n",
      "93\n",
      "30\n",
      "356\n",
      "355\n",
      "31\n",
      "225\n",
      "224\n",
      "32\n",
      "154\n",
      "153\n",
      "33\n",
      "129\n",
      "128\n",
      "34\n",
      "315\n",
      "314\n",
      "35\n",
      "127\n",
      "126\n",
      "36\n",
      "166\n",
      "165\n",
      "37\n",
      "211\n",
      "210\n",
      "38\n",
      "182\n",
      "181\n",
      "39\n",
      "143\n",
      "142\n",
      "40\n",
      "295\n",
      "294\n",
      "41\n",
      "141\n",
      "140\n",
      "42\n",
      "154\n",
      "153\n",
      "43\n",
      "239\n",
      "238\n",
      "44\n",
      "90\n",
      "89\n",
      "45\n",
      "131\n",
      "130\n",
      "46\n",
      "242\n",
      "241\n",
      "47\n",
      "160\n",
      "159\n",
      "48\n",
      "225\n",
      "224\n",
      "49\n",
      "326\n",
      "325\n",
      "50\n",
      "156\n",
      "155\n",
      "51\n",
      "196\n",
      "195\n",
      "52\n",
      "116\n",
      "115\n",
      "53\n",
      "196\n",
      "195\n",
      "54\n",
      "170\n",
      "169\n",
      "55\n",
      "171\n",
      "170\n",
      "56\n",
      "123\n",
      "122\n",
      "57\n",
      "225\n",
      "224\n",
      "58\n",
      "194\n",
      "193\n",
      "59\n",
      "135\n",
      "134\n",
      "60\n",
      "285\n",
      "284\n",
      "61\n",
      "256\n",
      "255\n",
      "62\n",
      "172\n",
      "171\n",
      "63\n",
      "202\n",
      "201\n",
      "64\n",
      "106\n",
      "105\n",
      "65\n",
      "214\n",
      "213\n",
      "66\n",
      "188\n",
      "187\n",
      "67\n",
      "140\n",
      "139\n",
      "68\n",
      "139\n",
      "138\n",
      "69\n",
      "90\n",
      "89\n",
      "70\n",
      "199\n",
      "198\n",
      "71\n",
      "136\n",
      "135\n",
      "72\n",
      "223\n",
      "222\n",
      "73\n",
      "138\n",
      "137\n",
      "74\n",
      "114\n",
      "113\n",
      "75\n",
      "204\n",
      "203\n",
      "76\n",
      "171\n",
      "170\n",
      "77\n",
      "197\n",
      "196\n",
      "78\n",
      "99\n",
      "98\n",
      "79\n",
      "165\n",
      "164\n",
      "80\n",
      "124\n",
      "123\n",
      "81\n",
      "206\n",
      "205\n",
      "82\n",
      "233\n",
      "232\n",
      "83\n",
      "213\n",
      "212\n",
      "84\n",
      "204\n",
      "203\n",
      "85\n",
      "130\n",
      "129\n",
      "86\n",
      "178\n",
      "177\n",
      "87\n",
      "130\n",
      "129\n",
      "88\n",
      "99\n",
      "98\n",
      "89\n",
      "130\n",
      "129\n",
      "90\n",
      "362\n",
      "361\n",
      "91\n",
      "256\n",
      "255\n",
      "92\n",
      "215\n",
      "214\n",
      "93\n",
      "184\n",
      "183\n",
      "94\n",
      "114\n",
      "113\n",
      "95\n",
      "158\n",
      "157\n",
      "96\n",
      "130\n",
      "129\n",
      "97\n",
      "123\n",
      "122\n",
      "98\n",
      "135\n",
      "134\n",
      "99\n",
      "184\n",
      "183\n",
      "100\n",
      "95\n",
      "94\n",
      "101\n",
      "143\n",
      "142\n",
      "102\n",
      "272\n",
      "271\n",
      "103\n",
      "269\n",
      "268\n",
      "104\n",
      "338\n",
      "337\n",
      "105\n",
      "125\n",
      "124\n",
      "106\n",
      "185\n",
      "184\n",
      "107\n",
      "170\n",
      "169\n",
      "108\n",
      "141\n",
      "140\n",
      "109\n",
      "202\n",
      "201\n",
      "110\n",
      "158\n",
      "157\n",
      "111\n",
      "244\n",
      "243\n",
      "112\n",
      "294\n",
      "293\n",
      "113\n",
      "193\n",
      "192\n",
      "114\n",
      "238\n",
      "237\n",
      "115\n",
      "142\n",
      "141\n",
      "116\n",
      "106\n",
      "105\n",
      "117\n",
      "199\n",
      "198\n",
      "118\n",
      "253\n",
      "252\n",
      "119\n",
      "135\n",
      "134\n",
      "120\n",
      "181\n",
      "180\n",
      "121\n",
      "114\n",
      "113\n",
      "122\n",
      "100\n",
      "99\n",
      "123\n",
      "134\n",
      "133\n",
      "124\n",
      "285\n",
      "284\n",
      "125\n",
      "124\n",
      "123\n",
      "126\n",
      "87\n",
      "86\n",
      "127\n",
      "94\n",
      "93\n",
      "128\n",
      "96\n",
      "95\n",
      "129\n",
      "186\n",
      "185\n",
      "130\n",
      "111\n",
      "110\n",
      "131\n",
      "114\n",
      "113\n",
      "132\n",
      "368\n",
      "367\n",
      "133\n",
      "156\n",
      "155\n",
      "134\n",
      "213\n",
      "212\n",
      "135\n",
      "171\n",
      "170\n",
      "136\n",
      "187\n",
      "186\n",
      "137\n",
      "278\n",
      "277\n",
      "138\n",
      "263\n",
      "262\n",
      "139\n",
      "169\n",
      "168\n",
      "140\n",
      "107\n",
      "106\n",
      "141\n",
      "251\n",
      "250\n",
      "142\n",
      "158\n",
      "159\n",
      "143\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs_teacher\u001b[39m\u001b[38;5;124m'\u001b[39m][i]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs_teacher\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(data.num_rows):\n",
    "    print(len(data['log_probs'][i][0]))\n",
    "    print(len(data['log_probs_teacher'][i]))\n",
    "    print(i)\n",
    "    assert len(data['log_probs'][i][0])-1==len(data['log_probs_teacher'][i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4ef996-8531-4837-b322-cda876158e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.016434656456112, -0.352039039134979, -0.313303917646408, -0.029853513464331002, -3.93382906622719e-05, -0.20064103603363, -0.00027926836628400003, -4.6491513785440475e-06, -0.003412378486245, -3.182837463100441e-05, -0.633067727088928, -0.007620431482791, -0.39467477798461903, -0.207727447152137, -0.026530675590038, 0.0, -0.8062194585800171, -0.012836328707635, -0.00030286493711100004, -0.018957853317260003, -0.44235873222351, -0.23087894916534402, -0.06290937215089701, -0.044039089232683, -0.081897713243961, -0.0021127776708450004, -0.00037222131504600003, -3.576278118089249e-07, -0.513729095458984, -1.017504215240478, -1.035511136054992, -0.004137171432375001, -1.311293544858926e-05, -0.000178440386662, -7.033323527139146e-06, -2.7298554414301183e-05, -1.430510451427835e-06, -0.43764889240264804, -0.005467580165714, -0.016074467450380003, -5.006777428206988e-06, -9.179073458653875e-06, -2.145764938177308e-06, -7.152531907195225e-06, -0.576463043689727, -0.005884229205548001, -0.840932965278625, -0.0017972521018230002, -0.20348392426967601, -1.430510451427835e-06, -0.005401777569204001, -0.051015265285968, -2.3722366677247923e-05, -0.001699671265669, -0.005132712423801001, -0.243351206183433, -4.2556810512905954e-05, -0.00026246439665500004, -4.1841583879431716e-05, -0.00016723664884900002, -0.654141426086425, -5.2808321925112984e-05, -0.9361624121665951, -3.576278118089249e-07, -0.038425210863351, -3.576278118089249e-07, -2.622600959512056e-06, -1.1682442163873931e-05, -0.292217969894409, -0.039372771978378004, -4.410734163684538e-06, 0.0, -2.145744110748637e-05, -2.694093564059585e-05, -0.000995259732007, -0.6590801477432251, -0.067146636545658, -0.40969184041023204, -0.461959242820739, -0.017731131985783, -0.227981358766555, -0.37814059853553705, -1.0132738680113102e-05, -0.078917622566223, -1.1801649634435302e-05, -0.00044300279114300003, -1.072883037522842e-06, -0.00017236177518400002, -1.4543427823809902e-05, -8.22540732769994e-06, -0.20864060521125702, -2.384183062531519e-06, -0.043184999376535006, -0.606793999671936, -0.0012524626217780002, -0.19966752827167503, -0.202669709920883, -2.622600959512056e-06, -1.192092213386786e-06, -6.079655122448457e-06, -1.6689160474925302e-05, 0.0, 0.0, -1.668928689468883e-06, -0.012510277330875001, -0.7532441020011901, -0.67979210615158, -0.003986033145338, -0.001249486114829, -3.337854650453664e-06, -0.062075845897197, -0.00138294394128, -6.508615479106086e-05, -3.242440288886428e-05, -1.7881377516459902e-06, -0.002483143471181, -0.00019727191829500002, -0.072429925203323, -0.68706077337265, -0.012515811249613, -0.045661490410566004, -0.07031853497028301, -0.029806189239025, -0.142693176865577, -1.192092213386786e-06, -0.28291350603103604, -0.019345885142683, -0.42880812287330605, -0.043005049228668005, -2.7418097943154862e-06, -0.000265086331637, -5.3285133617464467e-05, -2.145764938177308e-06, -1.026505947113037, -0.000493881292641, -0.00020239688456000001, -7.390948667307384e-06, -5.006777428206988e-06, -0.001712761935777, -1.192092824453538e-07, -7.152555099310121e-07, -1.2755313036905133e-05, -0.009662170894443, -0.0034507510717950002, -5.9364465414546444e-05, 0.0, -1.072883037522842e-06, -0.010342337191104, -5.960462772236497e-07, -0.000394862407119, -0.20345444977283403, -5.960462772236497e-07, 0.0, 0.0, 0.0, -2.3841855067985288e-07, -0.000261749344645, -8.344646857949556e-07]\n"
     ]
    }
   ],
   "source": [
    "print(data['log_probs'][i][0]) # vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125005b0-7464-40f9-a6b5-38c655e3089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-26.625, -18.5, -16.25, -19.25, -15.0, -24.125, -25.25, -23.75, -29.375, -26.125, -22.5, -29.875, -16.0, -13.0, -24.5, -17.375, -20.375, -18.875, -16.75, -12.75, -14.8125, -15.9375, -21.125, -16.0, -18.125, -17.375, -27.875, -22.0, -31.875, -20.0, -24.125, -17.5, -19.625, -31.375, -20.75, -26.875, -23.75, -19.375, -17.75, -22.625, -20.0, -32.0, -23.625, -21.875, -28.25, -17.0, -22.75, -15.5, -22.5, -21.5, -13.375, -18.5, -18.125, -20.5, -17.75, -20.25, -20.0, -24.625, -26.5, -19.0, -27.0, -24.5, -28.5, -26.625, -20.375, -19.125, -31.875, -18.5, -23.25, -27.0, -25.25, -23.625, -20.75, -29.875, -19.875, -29.125, -27.875, -22.875, -17.875, -18.5, -18.875, -14.4375, -25.5, -19.0, -19.5, -21.625, -28.875, -26.0, -25.375, -24.5, -10.625, -23.0, -21.875, -14.5625, -29.125, -24.5, -19.625, -21.125, -14.75, -30.125, -19.25, -22.25, -24.5, -32.5, -19.125, -28.5, -26.125, -18.125, -21.625, -23.5, -25.375, -17.0, -18.875, -18.75, -26.375, -19.875, -19.625, -25.375, -14.6875, -24.0, -22.125, -15.4375, -21.125, -21.25, -22.625, -27.25, -21.375, -18.875, -15.5625, -21.375, -18.125, -23.0, -26.75, -22.875, -22.375, -23.625, -31.625, -31.375, -23.875, -24.0, -18.0, -28.75, -16.75, -25.5, -30.625, -21.0, -23.0, -18.875, -27.0, -29.0, -21.5, -27.5, -33.25, -29.625, -25.75, -20.625, -22.25, -28.75, -34.75]\n"
     ]
    }
   ],
   "source": [
    "print(data['log_probs_teacher'][i]) # HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12882c13-d4dc-4ac3-a43a-d114d2d5cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9b335c-2789-4e0d-9432-91172fbd568b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836996557122539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.016434656456112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49987ad-b805-4799-aea7-22bbb0d96682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
