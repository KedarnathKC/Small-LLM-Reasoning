{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88babd32-577f-469f-889c-240ce1a93a71",
   "metadata": {},
   "source": [
    "#### One of the possible dataset in HF with the name WNC is:https://huggingface.co/datasets/reza-alipour/WNC/tree/main/data\n",
    "\n",
    "#### It is a gated repo, for which i have requested access. But not sure if it is the right one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f6738-6f28-454c-8c47-5a5c37d66f6d",
   "metadata": {},
   "source": [
    "#### So following CoEDIT, I am using there script as is to download and store the dataset \n",
    "\n",
    "https://github.com/facebookresearch/EditEval/blob/main/src/processors/wnc.py\n",
    "\n",
    "\n",
    "https://github.com/facebookresearch/EditEval/blob/main/src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3267660-f43c-43c5-981e-c6802b238db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac0eb73-7253-4d20-bc4f-d934cad9169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, root, filename=None):\n",
    "    \"\"\"Download a file from a url and place it in root.\n",
    "    Args:\n",
    "        url (str): URL to download file from\n",
    "        root (str): Directory to place downloaded file in\n",
    "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
    "    \"\"\"\n",
    "\n",
    "    root = os.path.expanduser(root)\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "    fpath = os.path.join(root, filename)\n",
    "\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        print(\"Downloading \" + url + \" to \" + fpath)\n",
    "        urllib.request.urlretrieve(url, fpath)\n",
    "    except (urllib.error.URLError, IOError) as e:\n",
    "        if url[:5] == \"https\":\n",
    "            url = url.replace(\"https:\", \"http:\")\n",
    "            print(\"Failed download. Trying https -> http instead.\" \" Downloading \" + url + \" to \" + fpath)\n",
    "            urllib.request.urlretrieve(url, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c19ffe-6daa-42ec-8e78-5c4c91276d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process(url, download_dir, filename):\n",
    "#     Lets first download the data\n",
    "    if not os.path.exists(download_dir):\n",
    "        download_url(url, download_dir, filename)\n",
    "        os.system(f\"unzip {os.path.join(download_dir, 'bias-corpus')} -d {download_dir}\")\n",
    "        os.system(f\"rm {os.path.join(download_dir, 'bias-corpus')}\")\n",
    "        \n",
    "        \n",
    "    original_columns = [\n",
    "            \"id\",\n",
    "            \"src_tok\",\n",
    "            \"tgt_tok\",\n",
    "            \"input\",\n",
    "            \"edits\",\n",
    "            \"src_POS_tags\",\n",
    "            \"tgt_parse_tags\",\n",
    "        ]\n",
    "\n",
    "    dfs = []\n",
    "    splits= [\"train\", \"dev\", \"test\"]\n",
    "    for split in splits:\n",
    "        full_path = os.path.join(download_dir, \"bias_data\", \"WNC\", \"biased.word.\" + split)\n",
    "        df = pd.read_csv(full_path, sep=\"\\t\", names=original_columns)\n",
    "        df[\"id\"] = df[\"id\"].apply(lambda x: \"wnc-\" + split + \"-\" + str(x))\n",
    "        df[\"wiki_id\"] = df[\"id\"].apply(lambda x: x)\n",
    "        dfs.append(df)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(dfs[0]) \n",
    "    dev_dataset = Dataset.from_pandas(dfs[1])\n",
    "    test_dataset = Dataset.from_pandas(dfs[2])\n",
    "    ds = DatasetDict(\n",
    "        {\n",
    "            \"train\": train_dataset,\n",
    "            \"val\": dev_dataset, \n",
    "            \"test\": test_dataset\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e89683-ae5b-4d23-bb0c-291c82618f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://bit.ly/bias-corpus\"\n",
    "download_dir='./wnc'\n",
    "filename='bias-corpus.zip'\n",
    "ds= download_and_process(url, download_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc08d510-6f18-4fab-a70c-d89a52479573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "        num_rows: 53803\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9263fa-8e6e-414a-9b55-4931acea1ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc2536ba0b24c208be31ae69de8c1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/53803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8784036a2b054e11b26868487b974e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd9b07d07d34aa48229353c716d4e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_path='/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/datasets/'\n",
    "ds.save_to_disk(dir_path+'neutralization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373bccea-37d5-4d9c-ad94-974d46a0cd49",
   "metadata": {},
   "source": [
    "### Spliting train set into feedback and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005ef8ce-3a8f-493f-8a78-5ba047c42875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17905b39-0aa6-495d-9249-7db4a100279c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "    num_rows: 53803\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=load_from_disk('../datasets/neutralization/train/')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fed8871-4b1b-4106-90c8-472472deda36",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_prompt': 'Given an input sentence, reason and replace the word with subjective bias to a word with neutral point of view. Consider the following types of biases:\\n1. framing biases use subjective words linked with a particular point of view (e.g. using words like best or deepest or using pilfered from instead of based on);\\n2. epistemological biases are linguistic features that subtly (often via presupposition) modify the believability of a proposition;\\n3. demographic biases are texts with presuppositions about particular genders, races, or other demographic categories (e.g. presupposing that all programmers are male).\\n\\nYour response should end with \"The neutralized text is [answer]\" where [answer] is the neutralized version of the input sentence.',\n",
       " 'system_msg': 'You are an expert in removing subjective biases in texts .',\n",
       " 'user_msg': 'Instruction:\\n{instruction}\\n\\nInput:\\n{question}',\n",
       " 'assistant_msg': '{rationale} The neutralized text is  {response}',\n",
       " 'few_shot': [{'id': 'wnc-train-131576896',\n",
       "   'input': 'gender-neutral pronouns used in ancient english',\n",
       "   'reference': 'gender-neutral pronouns used in middle english',\n",
       "   'rationale': 'The word ancient should be replaced by middle because \"ancient\" frames the time period in a more distant and perhaps less accurate way, while \"middle\" more precisely refers to the historical linguistic era known as Middle English. This corrects a framing bias by using a term that is both neutral and specific to the relevant linguistic context.'},\n",
       "  {'id': 'wnc-train-169899659',\n",
       "   'input': 'its adherents are christians who accept the hebrew text of genesis is a literal account that god created the earth in six 24-hour days, or believe that existing evidence in the natural world today supports a strict interpretation of scriptural creation as historical fact, or that the scientific evidence supporting darwinian evolution, geological uniformitarianism, and other theories which are at odds with a literal interpretation of the genesis creation account, are either flawed or misinterpreted.',\n",
       "   'reference': 'its adherents are christians who believe that the hebrew text of genesis is a literal account that god created the earth in six 24-hour days, or believe that existing evidence in the natural world today supports a strict interpretation of scriptural creation as historical fact, or that the scientific evidence supporting darwinian evolution, geological uniformitarianism, and other theories which are at odds with a literal interpretation of the genesis creation account, are either flawed or misinterpreted.',\n",
       "   'rationale': 'The word accept should be replaced by believe that because \"accept\" implies a level of objective endorsement or universal validity, whereas \"believe that\" more accurately reflects a subjective viewpoint. This replacement neutralizes an epistemological bias, making it clear that the statement reflects the adherents\\' personal beliefs rather than asserting them as objective facts.'},\n",
       "  {'id': 'wnc-train-712554371',\n",
       "   'input': 'sophie tucker (born sonya kalish, 18841966), actress, singer, and comedienne',\n",
       "   'reference': 'sophie tucker (born sonya kalish, 18841966), actress, singer, and comedian',\n",
       "   'rationale': 'The word comedienne should be replaced by comedian because comedienne is a gender-specific term that presupposes and reinforces a demographic bias by implying a distinction based on gender. Using the gender-neutral term comedian avoids unnecessary emphasis on gender and promotes a more inclusive and neutral point of view.'},\n",
       "  {'id': 'wnc-train-165621694',\n",
       "   'input': 'based on the motorola 68k series of microprocessors, the machine sported a custom chipset with advanced graphics and sound capabilities, and a sophisticated pre-emptive multitasking operating system (now known as amigaos).',\n",
       "   'reference': 'based on the motorola 68k series of microprocessors, the machine sported a custom chipset with advanced graphics and sound capabilities, and a pre-emptive multitasking operating system (now known as amigaos).',\n",
       "   'rationale': 'The word sophisticated should be deleted because it introduces a subjective evaluation. Neutralizing the sentence requires removing such evaluative language to maintain an objective tone.'},\n",
       "  {'id': 'wnc-train-417594576',\n",
       "   'input': \"horney distorted these needs somewhat to correspond with what she believed were individuals' neuroses.\",\n",
       "   'reference': \"horney modified these needs somewhat to correspond with what she believed were individuals' neuroses.\",\n",
       "   'rationale': 'The word distorted should be replaced by modified because \"modified\" conveys a more neutral and objective adjustment of the needs, while \"distorted\" carries a negative connotation implying misrepresentation or corruption, which biases the interpretation of Horney\\'s actions.'},\n",
       "  {'id': 'wnc-train-207072758',\n",
       "   'input': 'adequate testing for adverse health effects as well as performance data for these devices are seriously lacking.',\n",
       "   'reference': 'adequate testing for adverse health effects as well as performance data for these devices are lacking.',\n",
       "   'rationale': 'The word seriously should be deleted because it is an intensifier that adds subjective emphasis and is not necessary for a neutral, objective tone.'},\n",
       "  {'id': 'wnc-train-692108570',\n",
       "   'input': 'the show mainly revolves around alana \"big toe honey boo boo\" thompson and \"mama\" june \"the elephant man\" shannon and their family\\'s adventures in the redneck town of mcintyre, georgia.',\n",
       "   'reference': 'the show mainly revolves around alana \"big toe honey boo boo\" thompson and \"mama\" june \"the elephant man\" shannon and their family\\'s adventures in the southern town of mcintyre, georgia.',\n",
       "   'rationale': 'The word redneck should be replaced by southern because \"southern\" is a more neutral and regionally descriptive term, while \"redneck\" carries derogatory or stereotypical connotations that may be inappropriate or offensive.'},\n",
       "  {'id': 'wnc-train-693565497',\n",
       "   'input': 'settled in 1851, the town was christened salem crossing by the michigan southern railroad along whose tracks the community grew.',\n",
       "   'reference': 'settled in 1851, the town was named salem crossing by the michigan southern railroad along whose tracks the community grew.',\n",
       "   'rationale': 'The word christened should be replaced by named because named is a more neutral and standard term for assigning a name, whereas christened carries religious or ceremonial connotations that may not be appropriate in this historical context.'},\n",
       "  {'id': 'wnc-train-70218028',\n",
       "   'input': 'in december, under orders from clinton, arnold led a force of 1,600 troops into virginia and captured richmond, cutting off the major artery of materiel to the southern patriot effort.',\n",
       "   'reference': 'in december, under orders from clinton, arnold led a force of 1,600 troops into virginia and captured richmond, cutting off the major artery of materiel to the southern colonial effort.',\n",
       "   'rationale': 'The word patriot should be replaced by colonial because the term colonial is more neutral and descriptive, whereas patriot carries a subjective and valorizing tone.'},\n",
       "  {'id': 'wnc-train-879288389',\n",
       "   'input': 'the revolutionaries established the republic of hawaii, but their ultimate goal was the annexation of the islands to the united states, which finally occurred in 1898.',\n",
       "   'reference': 'the revolutionaries established the republic of hawaii, but their ultimate goal was the annexation of the islands to the united states, which occurred in 1898.',\n",
       "   'rationale': 'The word finally should be deleted because it adds an unnecessary evaluative emphasis on the timing of the annexation, which affects the neutrality of the statement.'},\n",
       "  {'id': 'wnc-train-88741599',\n",
       "   'input': 'between 1935 and 1937, butler served as a spokesman for the american league against war and fascism, which was considered by many to be communist-dominated, and gave numerous speeches to the communist party usa in the 1930s, as well as to pacifist groups.',\n",
       "   'reference': 'between 1935 and 1937, butler served as a spokesman for the american league against war and fascism, which was considered by many to be communist-dominated, and gave speeches to the communist party usa in the 1930s, as well as to pacifist groups.',\n",
       "   'rationale': 'The word numerous should be deleted because it adds emphasis that may not be necessary or neutral, and its removal results in a more objective and neutral tone.'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "task='neutralization'\n",
    "task_prompt_path=f'../prompts/{task}.json'\n",
    "with open(task_prompt_path) as fp:\n",
    "    task_prompt = json.load(fp)\n",
    "task_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a545f0-f65d-47de-9bb5-770afff846b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wnc-train-131576896',\n",
       " 'wnc-train-169899659',\n",
       " 'wnc-train-712554371',\n",
       " 'wnc-train-165621694',\n",
       " 'wnc-train-417594576',\n",
       " 'wnc-train-207072758',\n",
       " 'wnc-train-692108570',\n",
       " 'wnc-train-693565497',\n",
       " 'wnc-train-70218028',\n",
       " 'wnc-train-879288389',\n",
       " 'wnc-train-88741599']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_ids=[]\n",
    "for i in task_prompt['few_shot']:\n",
    "    few_shot_ids.append(i['id'])\n",
    "few_shot_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d12cab3b-90e8-40f4-becd-560bbb348ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "    num_rows: 53792\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.filter(lambda row:row['wiki_id'] not in few_shot_ids)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8950441c-40ae-494a-8cac-da0e6c506f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'src_tok', 'tgt_tok', 'input', 'edits', 'src_POS_tags', 'tgt_parse_tags', 'wiki_id'],\n",
       "    num_rows: 1600\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "feedback=train.shuffle(42).select(range(1600))\n",
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55902812-1843-4185-a648-92cf08394b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d4e93bb8074c18b1234700e695e9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feedback.save_to_disk('../datasets/neutralization/feedback-100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aafdf8d9-0371-4811-aa9a-bd80301f87ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the conservative akp appeals mostly to the religious segment of the turkish republic and erdoan's questionable political history has made some people suspicious of his motives.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback[1598]['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78ba22d-0ec4-433f-b599-368cd8daf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba18371-9c4a-4472-b0fa-cd0c931466c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://huggingface.co/api/spaces?filter=metric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_evaluation_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/evaluate/inspect.py:61\u001b[0m, in \u001b[0;36mlist_evaluation_modules\u001b[0;34m(module_type, include_community, with_details)\u001b[0m\n\u001b[1;32m     58\u001b[0m     evaluations_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module_type \u001b[38;5;129;01min\u001b[39;00m EVALUATION_MODULE_TYPES:\n\u001b[1;32m     60\u001b[0m         evaluations_list\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m---> 61\u001b[0m             \u001b[43m_list_evaluation_modules_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_community\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_community\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_details\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_details\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m EVALUATION_MODULE_TYPES:\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/evaluate/inspect.py:77\u001b[0m, in \u001b[0;36m_list_evaluation_modules_type\u001b[0;34m(module_type, include_community, with_details)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_list_evaluation_modules_type\u001b[39m(module_type, include_community\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, with_details\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m     r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(HF_LIST_ENDPOINT\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mmodule_type))\n\u001b[0;32m---> 77\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_community:\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/spaces?filter=metric"
     ]
    }
   ],
   "source": [
    "evaluate.list_evaluation_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b153574-5c8c-41fb-b3c2-2d359b5c5412",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find a module script at /scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/notebooks/sari/sari.py. Module 'sari' doesn't exist on the Hugging Face Hub either.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sari\u001b[38;5;241m=\u001b[39m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msari\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sources\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbout 95 species are currently accepted.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m predictions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbout 95 you now get in.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/evaluate/loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[1;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/evaluate/loading.py:681\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[1;32m    680\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find a module script at /scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/Small-LLM-Reasoning/notebooks/sari/sari.py. Module 'sari' doesn't exist on the Hugging Face Hub either."
     ]
    }
   ],
   "source": [
    "sari=load('sari')\n",
    "sources=[\"About 95 species are currently accepted.\"]\n",
    "predictions=[\"About 95 you now get in.\"]\n",
    "references=[[\"About 95 species are currently known.\",\"About 95 species are now accepted.\",\"95 species are now accepted.\"]]\n",
    "sari_score = sari.compute(sources=sources, predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f29bf-36a0-4e5b-ba18-aab12ad8dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
