{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12cf233-85f5-4343-b9d2-0c4a72f63fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = '/scratch3/workspace/wenlongzhao_umass_edu-reason/dev_kedar/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME']=cache_dir\n",
    "os.environ['HF_HUB_CACHE']=cache_dir+'/hub'\n",
    "hf_token=os.getenv('hf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6530e8e-e2d8-4779-821d-88329cb887a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/pi_mccallum_umass_edu/kchimmad_umass_edu/conda_envs/reason/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datasets import load_from_disk, Dataset, load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcc356a-3d38-44db-b7a4-45232181d1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 71\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_from_disk('../datasets/gsm8k/feedback/')\n",
    "data=data[0:71]\n",
    "data=Dataset.from_dict(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5adbbcb-15dc-44b6-bed6-a5ba6eee0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76eb418a-4980-441d-9b9f-22829f2f469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    answer = format_answer(examples['answer'])\n",
    "    # text = f'<|start_header_id|>user<|end_header_id|>\\n\\nGiven the following problem, reason and give a final answer to the problem.\\nProblem: {examples['question']}\\nYour response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}'\n",
    "    text = f'<|start_header_id|>user<|end_header_id|>\\n\\nGiven the following problem, reason and give a final answer to the problem.\\nProblem: {examples['question']}\\nYour response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}<|eot_id|>'\n",
    "    \n",
    "    return text\n",
    "\n",
    "def format_answer(answer):\n",
    "        answer = re.sub(r'<<.*?>>', '', answer)\n",
    "        answer = answer.replace('####', 'The final answer is')\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc66f49-69da-4f5b-be00-1693f424563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='meta-llama/Llama-3.2-3B-Instruct'\n",
    "output_dir= 'sft'\n",
    "add_special_tokens= True\n",
    "epochs= 5\n",
    "lr=1e-5 \n",
    "lr_scheduler_type= 'cosine'\n",
    "warmup= 0.1 \n",
    "weight_decay= 0.01\n",
    "per_device_train_batch_size= 4\n",
    "gradient_accumulation_steps= 4\n",
    "max_seq_length= 500 \n",
    "torch_dtype='bfloat16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538dfcf7-fa34-449f-9af7-02c3d26b456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import  SFTConfig, SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset, DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975c6ac9-99ae-48ac-af87-9539d1c16e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "response_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "# Set up the trainer\n",
    "training_args = SFTConfig(\n",
    "    model_init_kwargs={\n",
    "        \"torch_dtype\": \"bfloat16\",\n",
    "        \"cache_dir\":cache_dir\n",
    "    },\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    weight_decay=weight_decay,\n",
    "    warmup_ratio=warmup,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    # Using this 3072(prompt) + 512(output). The 3072(prompt) is taken from LLaMA : https://huggingface.co/datasets/meta-llama/Llama-3.2-1B-Instruct-evals?row=0\n",
    "    max_seq_length  = max_seq_length\n",
    ")\n",
    "\n",
    "training_args.add_special_tokens = add_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a80b1d-d422-4bd8-a979-63b0d40e2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26946/734675440.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 58.81it/s]\n",
      "Applying formatting function to train dataset: 100%|██████████| 71/71 [00:00<00:00, 11356.27 examples/s]\n",
      "Converting train dataset to ChatML: 100%|██████████| 71/71 [00:00<00:00, 17647.15 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 71/71 [00:00<00:00, 20416.54 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 71/71 [00:00<00:00, 2154.63 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 71/71 [00:00<00:00, 4551.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "        model=model_name,\n",
    "        args=training_args,\n",
    "        train_dataset=data,\n",
    "        formatting_func=formatting_prompts_func,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7f5f9d-eab3-444b-b943-c4fe53ec07bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 03:04, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.5624967098236084, metrics={'train_runtime': 185.8885, 'train_samples_per_second': 1.91, 'train_steps_per_second': 0.108, 'total_flos': 1192871346315264.0, 'train_loss': 0.5624967098236084})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0fee5-2a4e-49f3-befa-e2ca1ea567a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47a086-30c5-4b90-bab9-166f84b1e46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72815932-9427-47fc-ae7c-67a084646514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'token_ids', 'log_probs', 'all_returned_log_probs', 'model_answer', 'GT_Answer', 'score'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_data_path = '../outputs/exp-2.0.3/eval_1/generated_outputs.json'\n",
    "teacher_data = eacher_data=load_dataset('json',data_files=teacher_data_path)['train']\n",
    "teacher_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb90c0e9-161f-4be6-a50c-9b8bf383382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'gt_reasoning', 'gt_answer', 'student_token_ids', 'student_reasoning', 'student_answer', 'student_correctness', 'student_log_probs'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data_path='../outputs/exp-2.1.1/eval_1/logprobs.json'\n",
    "student_data=load_dataset('json', data_files=student_data_path)['train']\n",
    "student_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3583970-983d-458a-9315-8344b9cc176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path='../outputs/exp-2.1.1/eval_1/logprobs1.json'\n",
    "# logprobs=load_dataset('json', data_files=data_path)['train']\n",
    "# logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1af6fb-21d1-4021-898d-9204e8c72525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02e54d1-8009-41a7-ab64-01fd7abcf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_prob_ratio(teacher_log_prob, student_log_prob):\n",
    "    tr_stu_logprob=[]\n",
    "    student_logprob=[]\n",
    "    teacher_logprob=[]\n",
    "    for i in range(len(teacher_log_prob)):\n",
    "        student_log_probs=np.array(student_log_prob[i])\n",
    "        teacher_log_probs=np.array(teacher_log_prob[i])\n",
    "        student_logprob.append(np.mean(student_log_probs))\n",
    "        teacher_logprob.append(np.mean(teacher_log_probs))\n",
    "        tr_stu_logprob.append(\n",
    "            np.subtract(\n",
    "                np.mean(teacher_log_probs),\n",
    "                np.mean(student_log_probs)\n",
    "            )\n",
    "        )\n",
    "                \n",
    "    return tr_stu_logprob\n",
    "def merge_and_sample_data(data,teacher_data,student_data, remove_incorrects, sampling_ratio, seed=42 ):\n",
    "    # print(teacher_data['log_probs'][1])\n",
    "    # print(len(teacher_data['log_probs']))\n",
    "    tr_stu_logprob_ratio=get_log_prob_ratio(teacher_data['log_probs'],student_data['student_log_probs'])\n",
    "    threshold=np.median(tr_stu_logprob_ratio)\n",
    "    teacher_answers=[]\n",
    "    teacher_scores=[]\n",
    "    print(f'Median teacher-student-logprob-ratio: {threshold}')\n",
    "    for i in range(teacher_data.num_rows):\n",
    "        teacher_answers.append(teacher_data['output'][i][0])\n",
    "        teacher_scores.append(teacher_data['score'][i])\n",
    "    questions=data['question']\n",
    "    new_data = {\n",
    "        'question': questions,\n",
    "        'answer': teacher_answers,\n",
    "        'score': teacher_scores,\n",
    "        'logprob_ratio':tr_stu_logprob_ratio\n",
    "    }\n",
    "    \n",
    "    data= Dataset.from_dict(new_data)\n",
    "\n",
    "    if remove_incorrects:\n",
    "        data= data.filter(lambda x: x['score']==1)\n",
    "    print(f'After removing incorrects from teacher:{data.num_rows}')\n",
    "    \n",
    "    \n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    total_size = len(data)\n",
    "    size_below = int(total_size * sampling_ratio)\n",
    "    size_above = total_size - size_below\n",
    "\n",
    "    below_thresh = data.filter(lambda example: example['logprob_ratio'] < threshold)\n",
    "    above_thresh = data.filter(lambda example: example['logprob_ratio'] >= threshold)\n",
    "    print(f'below threshold:{below_thresh.num_rows}')\n",
    "    print(f'above threshold:{above_thresh.num_rows}')\n",
    "\n",
    "    def upsample(ds, target_size):\n",
    "        if len(ds) == 0:\n",
    "            return ds  # Avoid divide-by-zero\n",
    "        indices = [rng.randint(0, len(ds) - 1) for _ in range(target_size)]\n",
    "        return ds.select(indices)\n",
    "\n",
    "    sampled_below = upsample(below_thresh, size_below)\n",
    "    sampled_above = upsample(above_thresh, size_above)\n",
    "\n",
    "    data = concatenate_datasets([sampled_below, sampled_above])\n",
    "    return data.shuffle(seed=seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6f20b2-2d51-4bb1-aa29-bff77e7cc59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median teacher-student-logprob-ratio: 0.06102693236978156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1000/1000 [00:00<00:00, 235993.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing incorrects from teacher:951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 951/951 [00:00<00:00, 115990.09 examples/s]\n",
      "Filter: 100%|██████████| 951/951 [00:00<00:00, 114864.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below threshold:475\n",
      "above threshold:476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'score', 'logprob_ratio'],\n",
       "    num_rows: 951\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_and_sample_data(data, teacher_data, student_data, True, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94b3de-50a0-43e3-8490-202755a606f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96539318-7270-425c-a4eb-722d0bb9319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8da148-bb6f-4ff9-95fa-395f2b0c8120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f795809-7252-42cc-b683-027c22765c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def formatting_prompts_func(examples):\n",
    "    answer = format_answer(examples['answer'])\n",
    "    text = f'<|start_header_id|>user<|end_header_id|>\\n\\nGiven the following problem, reason and give a final answer to the problem.\\nProblem: {examples['question']}\\nYour response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}'\n",
    "    return text\n",
    "\n",
    "def format_answer(answer):\n",
    "        answer = re.sub(r'<<.*?>>', '', answer)\n",
    "        answer = answer.replace('####', 'The final answer is')\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab0583da-8704-4bb8-8411-7b2ce2a8f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "hf_token = os.getenv(\"hf_token\")\n",
    "\n",
    "# model_name= \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_name= \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_name= \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_name= \"meta-llama/Llama-3.2-3B\"\n",
    "# model_name= \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0865138d-a44f-4752-a21f-a8c91d2e3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Given the following problem, reason and give a final answer to the problem.\n",
      "Problem: Nicole collected 400 Pokemon cards. Cindy collected twice as many, and Rex collected half of Nicole and Cindy's combined total. If Rex divided his card equally among himself and his three younger siblings, how many cards does Rex have left?\n",
      "Your response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Cindy has 400 x 2 = 800 cards.\n",
      "Nicole and Cindy have 400 + 800 = 1200 cards.\n",
      "Rex has 1200/2 = 600 cards.\n",
      "Rex is left with 600/(3+1=4) = 150 cards\n",
      "The final answer is 150\n"
     ]
    }
   ],
   "source": [
    "examples={'question':data['question'][0], 'answer':data['answer'][0]}\n",
    "formatted = formatting_prompts_func(data[0])\n",
    "print(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43653924-7652-4c9b-9ee7-c00961356893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [128000, 128006, 882, 128007, 271, 22818, 279, 2768, 3575, 11, 2944, 323, 3041, 264, 1620, 4320, 311, 279, 3575, 627, 32298, 25, 45130, 14890, 220, 3443, 28831, 7563, 13, 70431, 14890, 11157, 439, 1690, 11, 323, 42907, 14890, 4376, 315, 45130, 323, 70431, 596, 11093, 2860, 13, 1442, 42907, 18255, 813, 3786, 18813, 4315, 5678, 323, 813, 2380, 14992, 37783, 11, 1268, 1690, 7563, 1587, 42907, 617, 2163, 5380, 7927, 2077, 1288, 842, 449, 330, 791, 1620, 4320, 374, 510, 9399, 19727, 1405, 510, 9399, 60, 374, 279, 2077, 311, 279, 3575, 627, 128009, 128006, 78191, 128007, 271, 34, 50090, 706, 220, 3443, 865, 220, 17, 284, 220, 4728, 7563, 627, 58916, 1286, 323, 70431, 617, 220, 3443, 489, 220, 4728, 284, 220, 4364, 15, 7563, 627, 49, 327, 706, 220, 4364, 15, 14, 17, 284, 220, 5067, 7563, 627, 49, 327, 374, 2163, 449, 220, 5067, 12148, 18, 10, 16, 28, 19, 8, 284, 220, 3965, 7563, 198, 791, 1620, 4320, 374, 220, 3965], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(formatted)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be7236d-7f2d-4a5d-9b52-420d2e0574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ĊĊ', 'Given', 'Ġthe', 'Ġfollowing', 'Ġproblem', ',', 'Ġreason', 'Ġand', 'Ġgive', 'Ġa', 'Ġfinal', 'Ġanswer', 'Ġto', 'Ġthe', 'Ġproblem', '.Ċ', 'Problem', ':', 'ĠNicole', 'Ġcollected', 'Ġ', '400', 'ĠPokemon', 'Ġcards', '.', 'ĠCindy', 'Ġcollected', 'Ġtwice', 'Ġas', 'Ġmany', ',', 'Ġand', 'ĠRex', 'Ġcollected', 'Ġhalf', 'Ġof', 'ĠNicole', 'Ġand', 'ĠCindy', \"'s\", 'Ġcombined', 'Ġtotal', '.', 'ĠIf', 'ĠRex', 'Ġdivided', 'Ġhis', 'Ġcard', 'Ġequally', 'Ġamong', 'Ġhimself', 'Ġand', 'Ġhis', 'Ġthree', 'Ġyounger', 'Ġsiblings', ',', 'Ġhow', 'Ġmany', 'Ġcards', 'Ġdoes', 'ĠRex', 'Ġhave', 'Ġleft', '?Ċ', 'Your', 'Ġresponse', 'Ġshould', 'Ġend', 'Ġwith', 'Ġ\"', 'The', 'Ġfinal', 'Ġanswer', 'Ġis', 'Ġ[', 'answer', ']\"', 'Ġwhere', 'Ġ[', 'answer', ']', 'Ġis', 'Ġthe', 'Ġresponse', 'Ġto', 'Ġthe', 'Ġproblem', '.Ċ', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'ĊĊ', 'C', 'indy', 'Ġhas', 'Ġ', '400', 'Ġx', 'Ġ', '2', 'Ġ=', 'Ġ', '800', 'Ġcards', '.Ċ', 'Nic', 'ole', 'Ġand', 'ĠCindy', 'Ġhave', 'Ġ', '400', 'Ġ+', 'Ġ', '800', 'Ġ=', 'Ġ', '120', '0', 'Ġcards', '.Ċ', 'R', 'ex', 'Ġhas', 'Ġ', '120', '0', '/', '2', 'Ġ=', 'Ġ', '600', 'Ġcards', '.Ċ', 'R', 'ex', 'Ġis', 'Ġleft', 'Ġwith', 'Ġ', '600', '/(', '3', '+', '1', '=', '4', ')', 'Ġ=', 'Ġ', '150', 'Ġcards', 'Ċ', 'The', 'Ġfinal', 'Ġanswer', 'Ġis', 'Ġ', '150']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(input_ids[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b23d5-f0ec-4bfb-9de2-95d566360b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reason",
   "language": "python",
   "name": "reason"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
