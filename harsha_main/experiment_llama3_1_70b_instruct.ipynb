{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5edc6123-5619-461d-bdba-be0cd1404a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: accelerate in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (1.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from accelerate) (2.4.1)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.4)\n",
      "Requirement already satisfied: jinja2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.77)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: xxhash, tzdata, requests, pyarrow, fsspec, dill, pandas, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "Successfully installed datasets-3.0.1 dill-0.3.8 fsspec-2024.6.1 multiprocess-0.70.16 pandas-2.2.3 pyarrow-17.0.0 requests-2.32.3 tzdata-2024.2 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00a1c00-5e3b-4cc7-8940-331a738c30b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (0.25.2)\n",
      "Requirement already satisfied: filelock in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from huggingface_hub) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: requests in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ce5ab9-89f4-4c5e-a180-812e6587784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hrajanala_umass_edu/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088af55d-2a9c-47dc-9ed0-70d457d63e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2e519d-0b69-4430-94bb-f245a3aed8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51411a3821934674a042125aa1df040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()\n",
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59a8c98-d12f-4b29-8d71-89943af89966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/workspace/wenlongzhao_umass_edu-analyze/transformers_cache/llama3.1'\n",
    "cache_dir = '/scratch/workspace/wenlongzhao_umass_edu-analyze/transformers_cache/llama3.1'\n",
    "model_name = \"meta-llama/Llama-3.1-70B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15db8deb-1ecf-4d48-a027-138eedd78aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c11296acf934ce59b2def28fc536330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    device_map=\"auto\",\n",
    "    offload_state_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a3a716-e3a7-45c4-83a3-ef41d2c79c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question):\n",
    "    prompt=\"Answer the below question: \\n\\n Question:\\n\\n\"+question\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2657610-c03c-4f9a-880e-43234798a73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 8192)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=8192, out_features=8192, bias=False)\n",
       "          (k_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=8192, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=8192, out_features=8192, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)\n",
       "          (up_proj): Linear(in_features=8192, out_features=28672, bias=False)\n",
       "          (down_proj): Linear(in_features=28672, out_features=8192, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae12d40-8b94-459e-8941-92f8a32eb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart and helpful assistant. I want you to answer the next question with just the answer. What is UMass Amherst famous for? \n",
      "Being the largest public university in New England, having the top-ranked Isenberg School of Management, and being a top producer of Fulbright Scholars.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "inputs = \"You are a smart and helpful assistant. I want you to answer the next question with just the answer. What is UMass Amherst famous for?\"\n",
    "\n",
    "encoded_inputs = tokenizer(inputs, return_tensors=\"pt\").to(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "        output = model.generate(**encoded_inputs, max_length=500, num_return_sequences=1,  pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a396e85-c685-4e93-8faa-76ad6bf2a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1495\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_disk(\"../datasets/gsm8k/val/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1708756b-9d8c-4d22-b04e-6e2216e51caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_start = \"\"\"Let's solve math word problems step by step. For each problem, we'll:\n",
    "\n",
    "Break down the important information\n",
    "Plan our approach\n",
    "Solve one calculation at a time\n",
    "State our final answer clearly\n",
    "\n",
    "Here are some examples: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_end = \"\"\"Now you can solve the new problem using the same step-by-step approach. Remember to:\n",
    "\n",
    "Show all your work clearly.\n",
    "Label each calculation step.\n",
    "Use intermediate steps to break down complex calculations.\n",
    "Double-check your math.\n",
    "State your final answer separately with appropriate units.\n",
    "After generating the answer, stop generating any text. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca48737-3eab-4c11-90c4-27f78f590387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 896\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = load_from_disk(\"../datasets/gsm8k/train/\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32af5c9d-2b97-48c6-9fc1-dbac9acd8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = \"\"\n",
    "for i in range(9):\n",
    "        few_shot_examples += \"Problem : \"+data_train[\"question\"][i]+\"\\nSolution : \"+data_train[\"answer\"][i]+\"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b163efc3-07b3-4719-9a76-7f9f672e4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_start + few_shot_examples + prompt_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506bd3c2-e14c-4f7d-a956-7b7773d4c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 5082\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feedback = load_from_disk(\"../datasets/gsm8k/feedback/\")\n",
    "data_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45071e7e-2974-45cc-afc1-c73ad47e5c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexandre read 120 * 1/10 = <<120*1/10=12>>12 novels.\\nSo, Jordan read 120 - 12 = <<120-12=108>>108 novels more than Alexandre.\\n#### 108'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = prompt +  \"Problem : \"+data_feedback[\"question\"][0]+\"\\nSolution : \"\n",
    "answer = data_feedback[\"answer\"][0]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e385e28-a25f-45bd-bcac-e677c0d2337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Let's solve math word problems step by step. For each problem, we'll:\n",
      "\n",
      "Break down the important information\n",
      "Plan our approach\n",
      "Solve one calculation at a time\n",
      "State our final answer clearly\n",
      "\n",
      "Here are some examples: \n",
      "\n",
      "Problem : Bobby wanted pancakes for breakfast.  The recipe on the box makes 21 pancakes.  While he ate 5 pancakes, his dog jumped up and was able to eat 7 before being caught.  How many pancakes does Bobby have left?\n",
      "Solution : Bobby ate 5 pancakes and his dog ate 7 so 5+7 = <<5+7=12>>12\n",
      "The recipe makes 21 pancakes and 12 were eaten so 21-12 = <<21-12=9>>9 pancakes were left\n",
      "#### 9\n",
      "\n",
      "Problem : A store gives a 10% discount for the amount of the sell that was over $1000.  John buys 7 items that each cost $200.  What does his order cost after the discount?\n",
      "Solution : His order came out to 7*200=$<<7*200=1400>>1400\n",
      "So there was 1400-1000=$<<1400-1000=400>>400 that qualified for the discount\n",
      "So his discount saved 400*.1=$<<400*.1=40>>40\n",
      "So his purchase came out to 1400-40=$<<1400-40=1360>>1360\n",
      "#### 1360\n",
      "\n",
      "Problem : An agricultural cooperative must ship 6500 kg of potatoes. During transport by truck, 150 kg are damaged and therefore cannot be sold. The potatoes are distributed in 50 kg bags, each bag being sold for $72. What will the sale of the potatoes bring?\n",
      "Solution : There are 6500 kg – 150 kg = <<6500-150=6350>>6350 kg of sellable potatoes.\n",
      "These will fit into 6350 kg / 50 kg/bag = <<6350/50=127>>127 bags\n",
      "In total, these will be sold for 127 bags * $72/bag = $<<127*72=9144>>9144\n",
      "#### 9144\n",
      "\n",
      "Problem : Tony read 23 books, Dean read 12 books and Breanna read 17 books. Tony and Dean read 3 of the same books and all three had read the same book as well. In total how many different books have Tony, Dean, and Breanna read?\n",
      "Solution : Tony and Dean together read 23 + 12 = <<23+12=35>>35 books\n",
      "3 of these books were duplicates so Tony and Dean together read 35 - 3 = <<35-3=32>>32 unique books\n",
      "All three read 32 + 17 = <<32+17=49>>49 books\n",
      "Because the books are being counted three times, the book is counted 3 - 1 = <<3-1=2>>2 extra times.\n",
      "All together they have read 49 - 2 = <<49-2=47>>47 different books\n",
      "#### 47\n",
      "\n",
      "Problem : Jan is making candy necklaces for herself and a few friends. Everyone receives a candy necklace each and each candy necklace is made up of 10 pieces of candies. The pieces of candies come from blocks of candy, which each produce 30 pieces of candy. If Jan breaks down 3 blocks of candy and every single piece of candy from this is used in the candy necklaces, how many friends receive a candy necklace?\n",
      "Solution : There are a total of 3 blocks of candy * 30 pieces of candy per candy block = <<3*30=90>>90 pieces of candy.\n",
      "Using this, Jan can create 90 pieces of candy / 10 pieces of candy per candy necklace = <<90/10=9>>9 candy necklaces.\n",
      "As Jan is keeping a candy necklace too, there must have been enough candy necklaces for 9 candy necklaces – 1 candy necklace for Jan = <<9-1=8>>8 friends.\n",
      "#### 8\n",
      "\n",
      "Problem : Carla is dividing up insurance claims among 3 agents. Missy can handle 15 more claims than John, who can handle 30% more claims than Jan. If Jan can handle 20 claims, how many claims can Missy handle?\n",
      "Solution : First find the additional number of claims John can handle: 30% * 20 claims = <<30*.01*20=6>>6 claims\n",
      "Then add that amount to Jan's number of claims to find John's number of claims: 20 claims + 6 claims = <<20+6=26>>26 claims\n",
      "Then add the 15 additional claims Missy can handle to find her number: 26 claims + 15 claims = <<15+26=41>>41 claims\n",
      "#### 41\n",
      "\n",
      "Problem : Micah bought envelopes to send, and depending on the weight of the envelope he will need more stamps. If an envelope weighs more than 5 pounds, he will need 5 stamps. If it weighs less than that, it will only need 2 stamps. If he bought 52 stamps with 6 envelopes that weigh less than 5 pounds, how many envelopes in total did Micah need to buy?\n",
      "Solution : Micah had to buy 6*2=<<6*2=12>>12 stamps for 6 envelopes less than 5 pounds.\n",
      "He has 52-12=<<52-12=40>>40 more stamps to buy.\n",
      "There are 40/5=<<40/5=8>>8 envelopes that weigh more than 5 pounds.\n",
      "Micah needed to buy 8+6=<<8+6=14>>14 envelopes.\n",
      "#### 14\n",
      "\n",
      "Problem : Chris has twelve marbles, and Ryan has twenty-eight marbles. If they put marbles together in a pile and then each takes away 1/4 of marbles from the pile, calculate the number of marbles remaining in the pile.\n",
      "Solution : If Chris and Ryan put together their marbles in a pile, the pile will have 12+28 = <<12+28=40>>40 marbles.\n",
      "If they then take 1/4 of the marbles each, every person will receive 1/4*40 = <<1/4*40=10>>10 marbles.\n",
      "Both of them will have taken a total of 10+10 = <<10+10=20>>20 marbles.\n",
      "The number of marbles remaining in the pile is 40-20 = <<40-20=20>>20\n",
      "#### 20\n",
      "\n",
      "Problem : Last year Dallas was 3 times the age of his sister Darcy. Darcy is twice as old as Dexter who is 8 right now. How old is Dallas now?\n",
      "Solution : Darcy = 2*Dexter = 2*8 = 16\n",
      "Last year Darcy was 16 - 1 = <<16-1=15>>15\n",
      "Dallas was 3 times Darcy last year = 3*15 = <<3*15=45>>45\n",
      "Dallas is a year older now = 45 + 1 = <<45+1=46>>46\n",
      "Dallas is 46 years old now.\n",
      "#### 46\n",
      "\n",
      "Now you can solve the new problem using the same step-by-step approach. Remember to:\n",
      "\n",
      "Show all your work clearly.\n",
      "Label each calculation step.\n",
      "Use intermediate steps to break down complex calculations.\n",
      "Double-check your math.\n",
      "State your final answer separately with appropriate units.\n",
      "After generating the answer, stop generating any text. \n",
      "\n",
      "\n",
      "Problem : Jordan read 120 French novels last holiday. His brother Alexandre read 1/10 of what Jordan read. How many more novels did Jordan read than Alexandre?\n",
      "Solution : 120 * 1/10 = <<120*1/10=12>>12 novels read by Alexandre\n",
      "120 - 12 = <<120-12=108>>108 more novels read by Jordan\n",
      "#### 108\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(input_text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "        output = model.generate(**encoded_inputs,max_new_tokens=1024, num_return_sequences=1,  pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "168fc2fc-534c-46e4-aa6c-c3a02cc8ad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:10<00:00, 62.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 310.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, padding_side=\"left\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.device_map = \"auto\"\n",
    "\n",
    "start_time = time.time()\n",
    "generated_outputs = []\n",
    "\n",
    "# Process all inputs at once\n",
    "batch_size = 4\n",
    "questions = data_feedback[\"question\"][:20]\n",
    "answers = data_feedback[\"answer\"][:20]\n",
    "n_samples = len(questions)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, n_samples, batch_size)):\n",
    "    batch_questions = questions[i : i + batch_size]\n",
    "    batch_answers = answers[i : i + batch_size]\n",
    "    # Prepare batch inputs - tokenize all at once\n",
    "    batch_inputs = tokenizer(\n",
    "        [prompt + \"Problem : \" + q + \"\\nSolution : \" for q in batch_questions],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(0)\n",
    "\n",
    "    # Generate for entire batch at once\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **batch_inputs,\n",
    "            max_length=2000,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    # Decode all outputs at once\n",
    "    texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    # Process outputs\n",
    "    for text, question, actual_answer in zip(texts, batch_questions, batch_answers):\n",
    "        lines = text.splitlines()\n",
    "        linenumber = [i for i, line in enumerate(lines) if line.startswith(\"Solution : \")][-1]\n",
    "        answer = \"\\n\".join(lines[linenumber:])\n",
    "        \n",
    "        generated_outputs.append({\n",
    "            \"input\": question,\n",
    "            \"output\": answer[11:],\n",
    "            \"actual_output\": actual_answer\n",
    "        })\n",
    "\n",
    "print(f\"Time taken: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8eae60-fe2a-41cb-96d4-a9ff5e278db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open(\"../outputs_70B/gsm8k/generated_outputs_test_70B.json\", \"w\") as f:\n",
    "    json.dump(generated_outputs, f, indent=4)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976f372-21a2-4ba7-8e26-82030f833ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
